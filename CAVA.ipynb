{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73e2a5a978394cef85d44b62e0cc5e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef2ddb11276a4e70940a1913b04ebb72",
              "IPY_MODEL_d4487aeb5828404e85403a41f0aeb918",
              "IPY_MODEL_a15494e759d441d2bef2618710146d84"
            ],
            "layout": "IPY_MODEL_de259db110e540ce9e2e27db46b60d07"
          }
        },
        "ef2ddb11276a4e70940a1913b04ebb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c5649b160d4828a15e983b6d52e6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_dd18d6b139994167ae9b14ed30fedf20",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d4487aeb5828404e85403a41f0aeb918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427843f0d13744cd94b0d479d00df563",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8ff1f51cbe54821980b34074b1a1f54",
            "value": 8
          }
        },
        "a15494e759d441d2bef2618710146d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430e5d5d4cab45279528fad11dee95b8",
            "placeholder": "​",
            "style": "IPY_MODEL_4a7a38f1e58949b1806610ce615c3748",
            "value": " 8/8 [00:08&lt;00:00,  1.09it/s]"
          }
        },
        "de259db110e540ce9e2e27db46b60d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c5649b160d4828a15e983b6d52e6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd18d6b139994167ae9b14ed30fedf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427843f0d13744cd94b0d479d00df563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ff1f51cbe54821980b34074b1a1f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "430e5d5d4cab45279528fad11dee95b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7a38f1e58949b1806610ce615c3748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **C**hain of **A**gent with chain of **V**erific**A**tion (CAVA)\n"
      ],
      "metadata": {
        "id": "yUqOfW0qDSsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "TR8XXMxGDlHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KJ08UiFnDOMN"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-core langchain-text-splitters langchain-community langgraph langchain_chroma langchain-huggingface langsmith\n",
        "!pip install -qU pypdf\n",
        "!pip install -qU langchain-google-genai\n",
        "# !pip install -qU optimum"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "tVoq_pKSD5jY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create LLM Model\n",
        "# from langchain.chat_models import init_chat_model\n",
        "\n",
        "# llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "id": "rQPMgb9Yewoa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# import os\n",
        "\n",
        "# token = os.environ[\"HUGGINGFACE_HUB_TOKEN\"]\n",
        "# login(token=token)"
      ],
      "metadata": {
        "id": "hD9730wZQ2hv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = userdata.get('HUGGINGFACE_HUB_TOKEN')\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "LPv-_Sb-PRbr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUNK_SIZE = 2000\n",
        "MAX_NEW_TOKENS = 128 # [TODO] ??create two pipelines with diff max_new_tokens if VRAM allows\n",
        "VERIFICATION_MODE = \"every_k\" # \"none\" | \"every\" | \"every_k\"\n",
        "VERIFICATION_K = 3\n"
      ],
      "metadata": {
        "id": "NSaD2XApkgiN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# print(sys.executable)\n",
        "\n",
        "# import transformers, optimum\n",
        "# print(\"transformers:\", transformers.__version__)\n",
        "# print(\"optimum:\", optimum.__version__)\n"
      ],
      "metadata": {
        "id": "oYE2vmVI5EKD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "# from awq import AutoAWQForCausalLM\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "# Disable grad for torch\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "def load_local_llm(model_id, max_new_tokens=MAX_NEW_TOKENS):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    # if \"AWQ\" in model_id:\n",
        "    #     model = AutoAWQForCausalLM.from_pretrained(\n",
        "    #         model_id,\n",
        "    #         device_map=\"auto\",\n",
        "    #         # dtype=torch.float16,\n",
        "    #         fuse_layers=True,\n",
        "    #         trust_remote_code=True,\n",
        "    #     )\n",
        "    # else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"auto\",\n",
        "        # dtype=torch.float16,\n",
        "    )\n",
        "    model.eval()\n",
        "    def _generate(prompt: str) -> str:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.inference_mode():\n",
        "            out = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=False,\n",
        "                use_cache=True,\n",
        "            )\n",
        "        # slice off prompt tokens\n",
        "        gen_ids = out[0, inputs[\"input_ids\"].shape[1]:]\n",
        "        text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "        return text.strip()\n",
        "\n",
        "    return RunnableLambda(lambda x: _generate(x))\n",
        "    # pipe = pipeline(\n",
        "    #     \"text-generation\",\n",
        "    #     model=model,\n",
        "    #     tokenizer=tokenizer,\n",
        "    #     max_new_tokens=max_new_tokens,\n",
        "    #     return_full_text=False,\n",
        "    #     model_kwargs={\"use_cache\": True},\n",
        "    # )\n",
        "\n",
        "    # return HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "# llm_strong = load_local_llm(\"Qwen/Qwen2.5-32B-Instruct-AWQ\", max_new_tokens=MAX_NEW_TOKENS)\n",
        "llm_strong = load_local_llm(\"Qwen/Qwen2.5-14B-Instruct\", max_new_tokens=MAX_NEW_TOKENS)\n",
        "# llm_fast = load_local_llm(\"Qwen/Qwen2.5-7B-Instruct\", max_new_tokens=MAX_NEW_TOKENS)\n",
        "\n",
        "# worker = llm_fast\n",
        "# manager = llm_strong\n",
        "# verifier = llm_strong\n",
        "# extractor = llm_fast\n",
        "\n",
        "worker = llm_strong\n",
        "manager = llm_strong\n",
        "verifier = llm_strong\n",
        "extractor = llm_strong"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "73e2a5a978394cef85d44b62e0cc5e3b",
            "ef2ddb11276a4e70940a1913b04ebb72",
            "d4487aeb5828404e85403a41f0aeb918",
            "a15494e759d441d2bef2618710146d84",
            "de259db110e540ce9e2e27db46b60d07",
            "09c5649b160d4828a15e983b6d52e6c7",
            "dd18d6b139994167ae9b14ed30fedf20",
            "427843f0d13744cd94b0d479d00df563",
            "c8ff1f51cbe54821980b34074b1a1f54",
            "430e5d5d4cab45279528fad11dee95b8",
            "4a7a38f1e58949b1806610ce615c3748"
          ]
        },
        "id": "wZQtfdtytF3u",
        "outputId": "f31f77a4-8ae2-4b10-a8d3-52ce47b898c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73e2a5a978394cef85d44b62e0cc5e3b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(llm_strong.pipeline.model.hf_device_map)\n",
        "# print(llm_fast.pipeline.model.hf_device_map)"
      ],
      "metadata": {
        "id": "srykrrVREHf9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = llm_strong.invoke(\"Testing testing testing\")"
      ],
      "metadata": {
        "id": "6D8KhETRFmRs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o = llm_fast.invoke(\"Testing testing testing\")"
      ],
      "metadata": {
        "id": "pj7EQB0OE6qq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "# model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_id,\n",
        "#     device_map=\"auto\",\n",
        "#     torch_dtype=\"auto\",\n",
        "# )\n",
        "\n",
        "# pipe = pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     max_new_tokens=MAX_NEW_TOKENS, # 32\n",
        "#     return_full_text=False,\n",
        "# )\n",
        "\n",
        "\n",
        "# # llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "# print(llm.invoke(\"What is an LLM?\"))\n"
      ],
      "metadata": {
        "id": "5Z-QI0nGPSgv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=int(CHUNK_SIZE*0.1),\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
        ")\n",
        "original_long_text = \"testing split text\" * 10\n",
        "\n",
        "chunks = splitter.split_text(original_long_text)\n",
        "chunks"
      ],
      "metadata": {
        "id": "TISheIqlPVyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ff3179-39d4-4b50-c016-e8f02ae75af9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['testing split texttesting split texttesting split texttesting split texttesting split texttesting split texttesting split texttesting split texttesting split texttesting split text']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split pure text\n",
        "\n",
        "# def split_text(text, chunk_size=500):\n",
        "#     chunks = []\n",
        "#     chunk_idx = 0\n",
        "#     while chunk_idx < len(text):\n",
        "#         end_idx = min(chunk_idx+chunk_size, len(text))\n",
        "#         chunks.append(text[chunk_idx:end_idx])\n",
        "#         chunk_idx = end_idx\n",
        "#     return chunks\n",
        "#     # return splitter.split_documents(text)\n",
        "\n",
        "# original_long_text = \"testing split text\" * 10\n",
        "# split_long_text = split_text(original_long_text, chunk_size=50)\n",
        "# split_long_text"
      ],
      "metadata": {
        "id": "DocimMLUkX51"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prompts ------------------------------------------------------------------\n",
        "# For QA Tasks\n",
        "WORKER_PROMPT = lambda i, query, chunk, prev: f\"\"\"\n",
        "You are Worker {i} in a chain solving a long-context question answering task.\n",
        "\n",
        "Use ONLY:\n",
        "- the current source text (chunk)\n",
        "- the previous worker summary\n",
        "\n",
        "Task:\n",
        "- Write a new summary that combines:\n",
        "  (a) all information from the previous summary that is relevant to the query, and\n",
        "  (b) any new relevant information in the current chunk.\n",
        "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
        "\n",
        "Constraints:\n",
        "- Maximum length: about 300 tokens.\n",
        "- Output only the new summary, no commentary about your process.\n",
        "\n",
        "Query:\n",
        "{query}\n",
        "\n",
        "Current source text (CHUNK {i}):\n",
        "{chunk}\n",
        "\n",
        "Previous worker summary:\n",
        "{prev}\n",
        "\n",
        "Now output the combined summary:\n",
        "\"\"\"\n",
        "\n",
        "# WORKER_PROMPT = lambda i, query, chunk, prev: f\"\"\"\n",
        "# You are Worker {i} in a chain solving a long-context task.\n",
        "# ONLY use the provided chunk and previous message.\n",
        "# You need to read current source text and summary of previous source text (if any),\n",
        "# and generate a summary to include them both and that best helps answer the query.\n",
        "# Keep ≤ 300 tokens. If no new info, forward previous message unchanged.\n",
        "\n",
        "# Query: {query}\n",
        "# Current source text: CHUNK {i} (do NOT reference other chunks):\\n{chunk}\\n\n",
        "# Previous source text :\\n{prev}\n",
        "# \"\"\"\n",
        "\n",
        "MANAGER_PROMPT = lambda query, final_worker_json: f\"\"\"\n",
        "You are the Manager in a HotpotQA question answering system.\n",
        "\n",
        "Task:\n",
        "- Read the summary of evidence.\n",
        "- Reason briefly about the answer.\n",
        "- Then output the final answer as a short span, try to find the closest answer.\n",
        "\n",
        "Output format (very important):\n",
        "1. First, write a short reasoning paragraph if needed.\n",
        "2. On the LAST line of your response, write exactly:\n",
        "\n",
        "   Final answer: <answer>\n",
        "\n",
        "Rules for <answer>:\n",
        "- Use the shortest possible span (a name, location, date, number, or \"yes\"/\"no\").\n",
        "- For yes/no questions, answer exactly \"yes\" or \"no\".\n",
        "- Do NOT add any text after <answer> on that line.\n",
        "- Do NOT write anything after the \"Final answer: ...\" line (no notes, no extra sentences).\n",
        "\n",
        "Query:\n",
        "{query}\n",
        "\n",
        "Summary of evidence:\n",
        "{final_worker_json}\n",
        "\"\"\"\n",
        "\n",
        "# MANAGER_PROMPT = lambda query, final_worker_json: f\"\"\"\n",
        "# You are the Manager. Read the summary and decide on the best possible answer.\n",
        "\n",
        "# Query:\n",
        "# {query}\n",
        "\n",
        "# Summary of evidence:\n",
        "# {final_worker_json}\n",
        "\n",
        "# First, reason briefly about the answer.\n",
        "# Then end with a line starting with: Final answer: <answer>\n",
        "\n",
        "# Make sure the final answer line contains the minimal answer span that should be evaluated.\n",
        "# \"\"\"\n",
        "# lambda query, final_worker_json: f\"\"\"\n",
        "# You are the Manager. Synthesize the final answer.\n",
        "# Please keep the final answer as short as possible and do not respond with full sentences.\n",
        "# Just reply with the final answer.\n",
        "# The source is too long and has been summarized. You need to answer based on the summary.\n",
        "\n",
        "# Query: {query}\n",
        "# Final worker Summary: {final_worker_json}\n",
        "# \"\"\"\n",
        "\n",
        "# ===== CoVe =====\n",
        "PLAN_VERIFICATIONS_PROMPT = lambda query, chunk, baseline_summary: f\"\"\"\n",
        "You are verifying a summary used in a long-context QA pipeline.\n",
        "\n",
        "Original Query: {query}\n",
        "\n",
        "Source chunk: {chunk}\n",
        "\n",
        "Baseline summary: {baseline_summary}\n",
        "\n",
        "Task:\n",
        "Generate a small list of concrete verification questions (2–4) that help check:\n",
        "- factual correctness\n",
        "- coverage of key information relevant to the query\n",
        "- absence of unsupported claims\n",
        "Return the verification questions as a numbered list.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "EXEC_VERIFICATIONS_PROMPT = lambda query, chunk, qa_block: f\"\"\"\n",
        "You are answering verification questions about a summary for a long-context QA pipeline.\n",
        "\n",
        "Original Query: {query}\n",
        "\n",
        "Source chunk: {chunk}\n",
        "\n",
        "Here is a list of verification questions:\n",
        "{qa_block}\n",
        "\n",
        "For each question, answer concisely.\n",
        "Formatting rules (very important):\n",
        "- Return your answers as a **single numbered list**.\n",
        "- Use exactly one line per answer.\n",
        "- Do NOT repeat the list.\n",
        "- Do NOT restate the questions.\n",
        "- The format must be:\n",
        "\n",
        "  1. <answer to Q1>\n",
        "  2. <answer to Q2>\n",
        "  3. <answer to Q3>\n",
        "  ...\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "GEN_FINAL_RESPONSE_PROMPT = lambda query, chunk, baseline_summary, questions, answers: f\"\"\"\n",
        "You are revising a summary for a long-context QA pipeline.\n",
        "\n",
        "Original Query: {query}\n",
        "\n",
        "Source chunk: {chunk}\n",
        "\n",
        "Baseline summary: {baseline_summary}\n",
        "\n",
        "Verification Q&A:\n",
        "{chr(10).join(f\"Q: {q}\\nA: {a}\" for q, a in zip(questions, answers))}\n",
        "\n",
        "Task:\n",
        "Write a revised summary that:\n",
        "- corrects any factual errors in the baseline summary\n",
        "- adds missing key information supported by the source chunk\n",
        "- removes unsupported or speculative claims\n",
        "- remains concise and focused on information relevant to the question\n",
        "\n",
        "Return ONLY the revised summary.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "EXTRACT_ANSWER_PROMPT = lambda query, manager_output: f\"\"\"\n",
        "You are post-processing the output of a QA system on the HotpotQA dataset.\n",
        "\n",
        "Your task: extract the **final answer string** that should be evaluated against the gold answer.\n",
        "\n",
        "Constraints (very important):\n",
        "- Return **only** the minimal answer span.\n",
        "- Do **not** include explanations, reasoning, or extra words.\n",
        "- Do **not** include phrases like \"The answer is\", \"It is\", \"Final answer\", etc.\n",
        "- Do **not** add punctuation at the beginning or end unless it is part of the entity (e.g., \"U.S.\").\n",
        "- Do **not** output multiple sentences.\n",
        "- If the question is yes/no, answer with exactly **yes** or **no**.\n",
        "- If the model’s answer is clearly wrong or missing, output exactly **no answer**.\n",
        "\n",
        "Output format:\n",
        "- Your entire response must be **only** the answer string, with no quotation marks and no additional text.\n",
        "\n",
        "Query:\n",
        "{query}\n",
        "\n",
        "Model's answer:\n",
        "{manager_output}\n",
        "\n",
        "Now output the answer string only:\n",
        "\"\"\"\n",
        "# lambda query, manager_output: f\"\"\"\n",
        "# You are post-processing the output of a QA system on the HotpotQA dataset.\n",
        "# Your task: extract the **final answer string** that should be evaluated against the gold answer.\n",
        "# Constraints (very important):\n",
        "# - Return **only** the minimal answer span.\n",
        "# - Do **not** include explanations, reasoning, or extra words.\n",
        "# - Do **not** include phrases like \"The answer is\", \"It is\", etc.\n",
        "# - Do **not** add punctuation at the beginning or end unless it is part of the entity (e.g., \"U.S.\").\n",
        "# - Do **not** output multiple sentences.\n",
        "# - If the question is yes/no, answer with exactly **\"yes\"** or **\"no\"**.\n",
        "# - If the model’s answer is clearly wrong or missing, output **\"no answer\"**.\n",
        "\n",
        "# HotpotQA style:\n",
        "# - Answers are usually short spans: a name, location, date, number, or \"yes\"/\"no\".\n",
        "# - Avoid extra context, titles, or clauses.\n",
        "\n",
        "# Query: {query}\n",
        "# Model's answer: {manager_output}\n",
        "\n",
        "# Now output ONLY the final answer span that should be scored by HotpotQA:\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "Xs8j8Qa4gXJJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define agent graph\n",
        "from typing import TypedDict, List\n",
        "\n",
        "# [TODO]\n",
        "class VerificationTrace(TypedDict):\n",
        "    worker_idx: int\n",
        "    baseline_summary: str\n",
        "    verification_questions: List[str]\n",
        "    verification_answers: List[str]\n",
        "    verified_summary: str\n",
        "\n",
        "\n",
        "class CoAState(TypedDict):\n",
        "    query: str\n",
        "    chunks: List[str]\n",
        "    i: int\n",
        "    worker_outputs: List[str]\n",
        "    verbose: bool\n",
        "    manager_output: str\n",
        "\n",
        "    verification_mode: str # \"none\" | \"every\" | \"every_k\"\n",
        "    verification_k: int\n",
        "    store_verification_traces: bool\n",
        "    verification_traces: List[VerificationTrace]\n"
      ],
      "metadata": {
        "id": "1cN0TvKjfuR9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_node(state: CoAState):\n",
        "    i = state[\"i\"]\n",
        "    chunk = state[\"chunks\"][i]\n",
        "    if i == 0:\n",
        "        prev = \"No Previous summaries\"\n",
        "    else:\n",
        "        # Get previous worker's output\n",
        "        # print(state[\"worker_outputs\"][i-1])\n",
        "        # prev = state[\"worker_outputs\"][i-1].content\n",
        "        prev = state[\"worker_outputs\"][i-1]\n",
        "    prompt = WORKER_PROMPT(i, state[\"query\"], chunk, prev)\n",
        "    if state[\"verbose\"]:\n",
        "        print(f\"Worker {i} with Prompt: \\n######{prompt}\\n#######\\n\")\n",
        "        print(\"worker invoke\")\n",
        "    out = worker.invoke(prompt)\n",
        "\n",
        "    if state[\"verbose\"]:\n",
        "        print(\"worker invoke -- done\")\n",
        "    # Note new outut\n",
        "    state[\"worker_outputs\"].append(out)\n",
        "    state[\"i\"] += 1\n",
        "    if state[\"verbose\"]:\n",
        "        # print(f\"Outputs: {out.content}\\n------------------\\n\\n\")\n",
        "        print(f\"Outputs: {out}\\n------------------\\n\\n\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def manager_node(state:CoAState):\n",
        "    if state[\"verbose\"]:\n",
        "        state[\"worker_outputs\"][-1]\n",
        "    # last_worker_output = state[\"worker_outputs\"][-1].content\n",
        "    last_worker_output = state[\"worker_outputs\"][-1]\n",
        "    prompt = MANAGER_PROMPT(state[\"query\"], last_worker_output)\n",
        "    if state[\"verbose\"]:\n",
        "        print(f\"Manager with Prompt: \\n######{prompt}\\n#######\\n\")\n",
        "    final_answer = manager.invoke(prompt)\n",
        "    # store final summary as last output\n",
        "    state[\"manager_output\"] = final_answer\n",
        "    if state[\"verbose\"]:\n",
        "        # print(f\"Manager Final Output: \\n#############\\n{final_answer.content}\")\n",
        "        print(f\"Manager Final Output: \\n#############\\n{final_answer}\")\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "8v8BKc5rnJrh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_numbered_answers(exec_text: str, num_questions: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    Parse a numbered list like:\n",
        "        1. Yes\n",
        "        2) No\n",
        "        3 - Maybe\n",
        "    into [\"Yes\", \"No\", \"Maybe\"], capped at num_questions.\n",
        "\n",
        "    Behavior:\n",
        "    - Ignore ALL lines until the first line beginning with a number.\n",
        "    - After that, parse consecutive numbered answers.\n",
        "    - Stop after num_questions items.\n",
        "    - Handle lines like \"4. Yes 1. Yes...\" by keeping only the first segment.\n",
        "    \"\"\"\n",
        "\n",
        "    answers: List[str] = []\n",
        "    started = False  # track when we hit first numbered line\n",
        "\n",
        "    for line in exec_text.split(\"\\n\"):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Detect first numbered line\n",
        "        if not started:\n",
        "            if line[0].isdigit():\n",
        "                started = True\n",
        "            else:\n",
        "                continue  # skip until list starts\n",
        "\n",
        "        # From here on, only accept numbered-list lines\n",
        "        if not line[0].isdigit():\n",
        "            continue\n",
        "\n",
        "        # Strip the leading number (1., 1), 1 -, etc.)\n",
        "        cleaned = re.sub(r\"^\\d+\\s*[\\.\\)\\-]\\s*\", \"\", line).strip()\n",
        "\n",
        "        # Remove any second inline numbering (avoid \"Yes 1. Yes, ...\"), keep only the part before it\n",
        "        parts = re.split(r\"\\s+\\d+\\s*[\\.\\)\\-]\\s*\", cleaned)\n",
        "        cleaned = parts[0].strip()\n",
        "\n",
        "        if cleaned:\n",
        "            answers.append(cleaned)\n",
        "            if len(answers) >= num_questions:\n",
        "                break\n",
        "\n",
        "    # Fallback if no valid parsed answers\n",
        "    if not answers:\n",
        "        return [exec_text.strip()]\n",
        "\n",
        "    return answers\n",
        "\n",
        "\n",
        "def run_cove(query: str, chunk: str, baseline_summary: str, worker_idx: int, verbose: bool = False) -> VerificationTrace:\n",
        "    # 1. Baseline response = baseline_summary (already produced by worker)\n",
        "    # 2. Plan verification questions\n",
        "    plan_prompt = PLAN_VERIFICATIONS_PROMPT(query, chunk, baseline_summary)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[CoVe][Worker {worker_idx}] Plan prompt:\\n{plan_prompt}\\n\")\n",
        "\n",
        "    plan_resp = verifier.invoke(plan_prompt)\n",
        "    plan_text = str(getattr(plan_resp, \"content\", plan_resp)) # Depending on the LLM wrapper, llm.invoke() may return a plain string or a message object AIMessage(..., content=\"some text\", ...)\n",
        "\n",
        "    # crude parsing: split into lines that look like questions\n",
        "    questions = [\n",
        "        line.strip(\" -0123456789.\").strip()\n",
        "        for line in plan_text.split(\"\\n\")\n",
        "        if \"?\" in line\n",
        "    ]\n",
        "    questions = [q for q in questions if q]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[CoVe][Worker {worker_idx}] Verification Questions:\\n{questions}\\n\")\n",
        "\n",
        "    # 3. Execute verifications (factored: one call per question)\n",
        "    answers = []\n",
        "    qa_block = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(questions))\n",
        "    exec_prompt = EXEC_VERIFICATIONS_PROMPT(query, chunk, qa_block)\n",
        "    exec_resp = verifier.invoke(exec_prompt)\n",
        "    exec_text = str(getattr(exec_resp, \"content\", exec_resp)).strip() #\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"verification q answer: {exec_text}\")\n",
        "\n",
        "    # answer parsing\n",
        "    parsed_answers = parse_numbered_answers(exec_text, num_questions=len(questions))\n",
        "\n",
        "    if len(parsed_answers) != len(questions):\n",
        "        questions_for_gen = [\"\\n\".join(questions)]\n",
        "        answers_for_gen = [exec_text]\n",
        "    else:\n",
        "        questions_for_gen = questions\n",
        "        answers_for_gen = parsed_answers\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[CoVe][Worker {worker_idx}] Answers:\\n{answers_for_gen}\\n\")\n",
        "\n",
        "    # 4. Generate final verified summary\n",
        "    final_prompt = GEN_FINAL_RESPONSE_PROMPT(query, chunk, baseline_summary, questions_for_gen, answers_for_gen)\n",
        "    if verbose:\n",
        "        print(f\"final_prompt: {final_prompt}\")\n",
        "    final_resp = verifier.invoke(final_prompt)\n",
        "    final_summary = str(getattr(final_resp, \"content\", final_resp)).strip() # [TODO] add in worker node? Depending on the LLM wrapper, llm.invoke() may return a plain string or a message object AIMessage(..., content=\"some text\", ...)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[CoVe][Worker {worker_idx}] Final verified summary:\\n{final_summary}\\n\")\n",
        "\n",
        "    trace: VerificationTrace = {\n",
        "        \"worker_idx\": worker_idx,\n",
        "        \"baseline_summary\": baseline_summary,\n",
        "        \"verification_questions\": questions,\n",
        "        \"verification_answers\": answers,\n",
        "        \"verified_summary\": final_summary,\n",
        "    }\n",
        "    return trace\n",
        "\n",
        "\n",
        "def verification_node(state: CoAState, worker_idx: int):\n",
        "    query = state[\"query\"]\n",
        "    chunk = state[\"chunks\"][worker_idx]\n",
        "\n",
        "    raw_summary = state[\"worker_outputs\"][worker_idx]\n",
        "    baseline_summary = str(getattr(raw_summary, \"content\", raw_summary)) #\n",
        "\n",
        "    trace = run_cove(\n",
        "        query=query,\n",
        "        chunk=chunk,\n",
        "        baseline_summary=baseline_summary,\n",
        "        worker_idx=worker_idx,\n",
        "        verbose=state[\"verbose\"],\n",
        "    )\n",
        "\n",
        "    # replace worker summary with verified one\n",
        "    state[\"worker_outputs\"][worker_idx] = trace[\"verified_summary\"]\n",
        "\n",
        "    # store trace if needed\n",
        "    if state.get(\"store_verification_traces\", False): # defaults to False if the key doesn’t exist\n",
        "        state[\"verification_traces\"].append(trace)\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def maybe_run_verification(state: CoAState) -> CoAState:\n",
        "    \"\"\"\n",
        "    determine if the latest generated summary needs to be verified\n",
        "\n",
        "    Param:\n",
        "    state (returned by worker_node())\n",
        "\n",
        "    Return:\n",
        "    updated state\n",
        "    \"\"\"\n",
        "    mode = state[\"verification_mode\"] # \"none\" | \"every\" | \"every_k\"\n",
        "    k = state[\"verification_k\"]\n",
        "    current_worker_idx = state[\"i\"] - 1 # cuz in worker_node() before returning state it does state[\"i\"] += 1\n",
        "\n",
        "    if mode == \"none\":\n",
        "        return state\n",
        "    if mode == \"every\":\n",
        "        return verification_node(state, current_worker_idx)\n",
        "    if mode == \"every_k\" and (current_worker_idx + 1) % k == 0:\n",
        "        return verification_node(state, current_worker_idx)\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "Z7SIQohOsuGT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_coa(query, context, verbose=True, verification_mode=\"none\", verification_k=1, store_verification_traces=True, postprocess=True): # chunk_size\n",
        "    # Split context\n",
        "    # chunks = split_text(context, chunk_size=chunk_size)\n",
        "    chunks = splitter.split_text(context)\n",
        "    if verbose:\n",
        "        print(\"Text Chunks: \",chunks)\n",
        "    # assert 1==2\n",
        "    # Initialize initial CoAState\n",
        "    init_state = {\n",
        "        \"query\": query,\n",
        "        \"chunks\": chunks,\n",
        "        \"i\": 0,\n",
        "        \"worker_outputs\": [],\n",
        "        \"verbose\": verbose,\n",
        "        \"manager_output\": \"\",\n",
        "        # [CoVe]\n",
        "        \"verification_mode\": verification_mode,\n",
        "        \"verification_k\": verification_k,\n",
        "        \"store_verification_traces\": store_verification_traces,\n",
        "        \"verification_traces\": []\n",
        "    }\n",
        "    state = init_state\n",
        "    length = len(chunks)\n",
        "    if verbose:\n",
        "        print(\"Num Chunks: \", length)\n",
        "    # Worker nodes, for each chunk\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        # Run worker node and get new state\n",
        "        if verbose:\n",
        "            print(f\"Running Worker {i}\")\n",
        "        state = worker_node(state)\n",
        "        if verbose:\n",
        "            print(f\"Running Worker {i} -- Done\")\n",
        "        # [TODO]\n",
        "        if verbose:\n",
        "            print(f\"Verifying Worker {i}\")\n",
        "        state = maybe_run_verification(state)\n",
        "        if verbose:\n",
        "            print(f\"Verifying Worker {i} -- Done\")\n",
        "\n",
        "    # At the end of the loop, state[\"i\"] should be == len(chunks)\n",
        "    assert state[\"i\"] == len(chunks), \"Total states worked does not equal to number of text chunks\"\n",
        "\n",
        "    # Finally run manager at last\n",
        "    if verbose:\n",
        "        print(f\"Manager producing output\")\n",
        "    state = manager_node(state)\n",
        "    # final_ans = state[\"worker_outputs\"][-1].content\n",
        "    final_ans = state[\"manager_output\"]\n",
        "    if verbose:\n",
        "        print(\"Final Answer before process: \", final_ans)\n",
        "    if \"Final Answer: \".lower() in final_ans.lower():\n",
        "        if verbose:\n",
        "            print(\"splitting parsing\")\n",
        "        final_ans = final_ans.lower().split(\"Final answer: \".lower())[-1]\n",
        "    if verbose:\n",
        "        print(f\"Manager producing output -- Done\")\n",
        "\n",
        "    # Post processing\n",
        "    if postprocess and False:\n",
        "        if verbose:\n",
        "            print(f\"Extractor\")\n",
        "        prompt = EXTRACT_ANSWER_PROMPT(query, state[\"manager_output\"])\n",
        "        resp = extractor.invoke(prompt)\n",
        "        final_ans = str(getattr(resp, \"content\", resp)).strip()\n",
        "        if verbose:\n",
        "            print(f\"Extractor -- Done\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Query: {state[\"query\"]}\\nFinal Answer: {final_ans}\")\n",
        "    return final_ans"
      ],
      "metadata": {
        "id": "9HRK_kL7mXbh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test run CoA\n",
        "# ans = run_coa(\"what is the meaning?\", original_long_text, chunk_size=50, verbose=False)\n",
        "# ans"
      ],
      "metadata": {
        "id": "0YtaRWUmswE7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans"
      ],
      "metadata": {
        "id": "KnMlBW_QtXZi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llPlkzBMjiOl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "jgh-IA0MwhNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MRIIYLU3hica",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78da164-5990-45d4-9dd8-3e1f3aa1d354"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [TODO]\n",
        "LOG_PATH = \"/content/drive/MyDrive/GenAI/project/logs/hotpotqa_valtest.jsonl\"\n",
        "SUBSET_START = 0\n",
        "SUBSET_END = 3\n",
        "NUM_SAMPLES_TO_LOAD = SUBSET_END - SUBSET_START # may need to load more\n",
        "SEED = 130"
      ],
      "metadata": {
        "id": "LnL4tKaMjRhS"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Callable\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. HotpotQA Loader\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def load_hotpotqa(split=\"validation\", max_samples=None):\n",
        "    \"\"\"\n",
        "    [source] https://huggingface.co/datasets/hotpotqa/hotpot_qa\n",
        "\n",
        "    an example in hotpotqa - fullwiki:\n",
        "    {\n",
        "        \"id\": str,\n",
        "        \"question\": str,\n",
        "        \"answer\": str,\n",
        "        \"type\": str,\n",
        "        \"level\": str,\n",
        "        \"supporting_facts\":\n",
        "        {\n",
        "            \"title\": [str, str, ...], # may repeat\n",
        "            \"sent_id\": [int32, int32, ...]\n",
        "        },\n",
        "        \"context\":\n",
        "        {\n",
        "            \"title\": [str, str, ...],\n",
        "            \"sentences\": [[str, str, str, ...], [str, str, str, ...], ...]\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "    Return:\n",
        "    a list of dicts\n",
        "    {\n",
        "        \"id\": HotpotQA string id,\n",
        "        \"idx\": int index within this split (for convenience),\n",
        "        \"question\": str,\n",
        "        \"answer\": str,\n",
        "        \"type\": \"bridge\" or \"comparison\",\n",
        "        \"level\": \"easy\"/\"medium\"/\"hard\",\n",
        "        \"context\":\n",
        "        [\n",
        "            { \"title\": str, \"sentences\": [str, str, ...] }, # doc 0\n",
        "            { \"title\": str, \"sentences\": [str, str, ...] }, # doc 1\n",
        "            ...\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    raw = load_dataset(\"hotpot_qa\", \"fullwiki\")[split]\n",
        "\n",
        "    # Generate random indicies\n",
        "\n",
        "    rng = random.Random(SEED)\n",
        "    indices = list(range(len(raw)))\n",
        "    rng.shuffle(indices)\n",
        "    indicies = indices[:max_samples]\n",
        "    print(\"Random sampled indicies: \", indicies)\n",
        "\n",
        "    data = []\n",
        "    for idx, item in enumerate(raw):\n",
        "        context = [\n",
        "            {\n",
        "                \"title\": t,\n",
        "                \"sentences\": sents\n",
        "            }\n",
        "            for t, sents in zip(item[\"context\"][\"title\"], item[\"context\"][\"sentences\"])\n",
        "        ]\n",
        "\n",
        "        data.append({\n",
        "            \"id\": item[\"id\"],                 # original HotpotQA id (string)\n",
        "            \"idx\": idx,                       # integer position in this split\n",
        "            \"question\": item[\"question\"],\n",
        "            \"answer\": item[\"answer\"],\n",
        "            \"type\": item.get(\"type\"),         # [TODO] ?? \"bridge\" or \"comparison\"\n",
        "            \"level\": item.get(\"level\"),       # [TODO] ?? \"easy\"/\"medium\"/\"hard\"\n",
        "            \"context\": context,\n",
        "        })\n",
        "\n",
        "        if max_samples and len(data) >= max_samples:\n",
        "            break\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Context Merger\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def merge_context_fullwiki(context):\n",
        "    \"\"\"\n",
        "    merge each document's sentence list into a single text string\n",
        "\n",
        "    Param:\n",
        "    context (return from load_hotpotqa()):\n",
        "    [\n",
        "        { \"title\": str, \"sentences\": [str, str, ...] }, # doc 0\n",
        "        { \"title\": str, \"sentences\": [str, str, ...] }, # doc 1\n",
        "        ...\n",
        "    ]\n",
        "\n",
        "    Return:\n",
        "    texts: list[str]\n",
        "    merged text for each document\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "\n",
        "    for doc in context:\n",
        "        text = \" \".join(doc[\"sentences\"])\n",
        "        texts.append(text)\n",
        "\n",
        "    return texts\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Evaluation Metrics (EM + F1)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"\n",
        "    Lowercase, remove punctuation/articles/extra whitespace.\n",
        "    \"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "# TODO: does the paper compute this at the token level??\n",
        "def f1_score(pred, gold):\n",
        "    pred_tokens = normalize_answer(pred).split()\n",
        "    gold_tokens = normalize_answer(gold).split()\n",
        "\n",
        "    if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
        "        return int(pred_tokens == gold_tokens)\n",
        "\n",
        "    common = set(pred_tokens) & set(gold_tokens)\n",
        "    num_same = sum(min(pred_tokens.count(t), gold_tokens.count(t)) for t in common)\n",
        "\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(gold_tokens)\n",
        "    return (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "\n",
        "def exact_match(pred, gold):\n",
        "    return normalize_answer(pred) == normalize_answer(gold)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Evaluation loop\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def evaluate(model_fn: Callable, dataset: List[Dict], log_path: str | None = None, flush_every: int = 10, include_context_in_log: bool = False):\n",
        "    \"\"\"\n",
        "    model_fn(query, context_chunks) -> str\n",
        "\n",
        "    If log_path is provided, per-sample metrics will be written to a JSONL file, one JSON object per line.\n",
        "    This allows:\n",
        "      - parallel eval on disjoint subsets\n",
        "      - later merging / error analysis\n",
        "    \"\"\"\n",
        "    # qs = []\n",
        "    # ctxs = []\n",
        "    # preds = []\n",
        "    # refs = []\n",
        "\n",
        "    f1s = []\n",
        "    ems = []\n",
        "    N = 0\n",
        "\n",
        "    # Open log file once (append mode so you can resume)\n",
        "    log_file = None\n",
        "    if log_path is not None:\n",
        "        os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
        "        log_file = open(log_path, \"a\", encoding=\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        for sample in tqdm(dataset, desc=\"Evaluating\"):\n",
        "            qid = sample.get(\"id\")\n",
        "            question = sample[\"question\"]\n",
        "            context = sample[\"context\"]\n",
        "            gold = sample[\"answer\"]\n",
        "\n",
        "            texts = merge_context_fullwiki(context)\n",
        "            pred = model_fn(question, texts)\n",
        "\n",
        "            f1 = f1_score(pred, gold)\n",
        "            em = int(exact_match(pred, gold))\n",
        "\n",
        "            f1s.append(f1)\n",
        "            ems.append(em)\n",
        "            N += 1\n",
        "\n",
        "            # Per-sample record for logging\n",
        "            record = {\n",
        "                \"id\": qid,\n",
        "                \"idx\": sample.get(\"idx\"),\n",
        "                \"type\": sample.get(\"type\"),\n",
        "                \"level\": sample.get(\"level\"),\n",
        "                \"question\": question,\n",
        "                \"gold_answer\": gold,\n",
        "                \"prediction\": pred,\n",
        "                \"f1\": f1,\n",
        "                \"em\": em,\n",
        "            }\n",
        "            if include_context_in_log:\n",
        "                record[\"context\"] = texts  # can be big; toggle with flag\n",
        "\n",
        "            if log_file is not None:\n",
        "                log_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "                # Periodic flush so progress is safely on disk\n",
        "                if N % flush_every == 0:\n",
        "                    log_file.flush()\n",
        "                    os.fsync(log_file.fileno())\n",
        "\n",
        "        # Final flush\n",
        "        if log_file is not None:\n",
        "            log_file.flush()\n",
        "            os.fsync(log_file.fileno())\n",
        "\n",
        "    finally:\n",
        "        if log_file is not None:\n",
        "            log_file.close()\n",
        "\n",
        "    return {\n",
        "        \"num_samples\": N,\n",
        "        \"f1\": sum(f1s) / N if N > 0 else 0.0,\n",
        "        \"em\": sum(ems) / N if N > 0 else 0.0,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Placeholder CoA model\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def coa_placeholder(question: str, context_texts: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Dummy version to make the pipeline runnable now.\n",
        "    Replace with Ray's CoA later.\n",
        "    \"\"\"\n",
        "    merged_context = \" \".join(context_texts)\n",
        "\n",
        "    # print(merged_context)\n",
        "    # prompt = f\"Context:\\n{merged_context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    # TODO\n",
        "    # print(f\"Length of merged context: {len(merged_context)}\")\n",
        "    # return \"hello\"\n",
        "    # assert 1==2\n",
        "    # TODO: Figure out what chunk size is best cost to performance\n",
        "    final_ans = run_coa(query=question, context=merged_context, verbose=True, verification_mode=VERIFICATION_MODE, verification_k=VERIFICATION_K, store_verification_traces=True)\n",
        "    return final_ans\n",
        "    return \"PLACEHOLDER YES\" # \"PLACEHOLDER_ANSWER\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. Running the pipeline\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Full Hotpot QA size is 7405, takes ~ 29 hours with 512 chunk size\n",
        "    data = load_hotpotqa(split=\"validation\", max_samples=NUM_SAMPLES_TO_LOAD)\n",
        "    subset = data[SUBSET_START:SUBSET_END]\n",
        "    results = evaluate(coa_placeholder, subset, log_path=LOG_PATH, flush_every=5, include_context_in_log=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "HIecN2liwiC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6f0693-253b-4774-ce1d-3a81cd1acd66"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sampled indicies:  [2554, 1722, 6283]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Chunks:  ['Adam Collis is an American filmmaker and actor.  He attended the Duke University from 1986 to 1990 and the University of California, Los Angeles from 2007 to 2010.  He also studied cinema at the University of Southern California from 1991 to 1997.  Collis first work was the assistant director for the Scott Derrickson\\'s short \"Love in the Ruins\" (1995).  In 1998, he played \"Crankshaft\" in Eric Koyanagi\\'s \"Hundred Percent\". Ed Wood is a 1994 American biographical period comedy-drama film directed and produced by Tim Burton, and starring Johnny Depp as cult filmmaker Ed Wood.  The film concerns the period in Wood\\'s life when he made his best-known films as well as his relationship with actor Bela Lugosi, played by Martin Landau.  Sarah Jessica Parker, Patricia Arquette, Jeffrey Jones, Lisa Marie, and Bill Murray are among the supporting cast. Tyler Bates (born June 5, 1965) is an American musician, music producer, and composer for films, television, and video games.  Much of his work is in the action and horror film genres, with films like \"Dawn of the Dead, 300, Sucker Punch,\" and \"John Wick.\"  He has collaborated with directors like Zack Snyder, Rob Zombie, Neil Marshall, William Friedkin, Scott Derrickson, and James Gunn.  With Gunn, he has scored every one of the director\\'s films; including \"Guardians of the Galaxy\", which became one of the highest grossing domestic movies of 2014, and its 2017 sequel.  In addition, he is also the lead guitarist of the American rock band Marilyn Manson, and produced its albums \"The Pale Emperor\" and \"Heaven Upside Down\". Doctor Strange is a 2016 American superhero film based on the Marvel Comics character of the same name, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures.  It is the fourteenth film of the Marvel Cinematic Universe (MCU).  The film was directed by Scott Derrickson, who wrote it with Jon Spaihts and C', '.  It is the fourteenth film of the Marvel Cinematic Universe (MCU).  The film was directed by Scott Derrickson, who wrote it with Jon Spaihts and C. Robert Cargill, and stars Benedict Cumberbatch as Stephen Strange, along with Chiwetel Ejiofor, Rachel McAdams, Benedict Wong, Michael Stuhlbarg, Benjamin Bratt, Scott Adkins, Mads Mikkelsen, and Tilda Swinton.  In \"Doctor Strange\", surgeon Strange learns the mystic arts after a career-ending car accident. Hellraiser: Inferno (also known as Hellraiser V: Inferno) is a 2000 American horror film.  It is the fifth installment in the \"Hellraiser\" series and the first \"Hellraiser\" film to go straight-to-DVD.  It was directed by Scott Derrickson and released on October 3, 2000.  The film concerns a corrupt detective who discovers Lemarchand\\'s box at a crime scene.  The film\\'s reviews were mixed. Sinister is a 2012 supernatural horror film directed by Scott Derrickson and written by Derrickson and C. Robert Cargill.  It stars Ethan Hawke as fictional true-crime writer Ellison Oswalt who discovers a box of home movies in his attic that puts his family in danger. Deliver Us from Evil is a 2014 American supernatural horror film directed by Scott Derrickson and produced by Jerry Bruckheimer.  The film is officially based on a 2001 non-fiction book entitled \"Beware the Night\" by Ralph Sarchie and Lisa Collier Cool, and its marketing campaign highlighted that it was \"inspired by actual accounts\".  The film stars Eric Bana, Édgar Ramírez, Sean Harris, Olivia Munn, and Joel McHale in the main roles and was released on July 2, 2014. Woodson is a census-designated place (CDP) in Pulaski County, Arkansas, in the United States.  Its population was 403 at the 2010 census.  It is part of the Little Rock–North Little Rock–Conway Metropolitan Statistical Area.  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century', '.  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century.  Woodson is adjacent to the Wood Plantation, the largest of the plantations own by Ed Wood Sr. Conrad Brooks (born Conrad Biedrzycki on January 3, 1931 in Baltimore, Maryland) is an American actor.  He moved to Hollywood, California in 1948 to pursue a career in acting.  He got his start in movies appearing in Ed Wood films such as \"Plan 9 from Outer Space\", \"Glen or Glenda\", and \"Jail Bait.\"  He took a break from acting during the 1960s and 1970s but due to the ongoing interest in the films of Ed Wood, he reemerged in the 1980s and has become a prolific actor.  He also has since gone on to write, produce and direct several films. The Exorcism of Emily Rose is a 2005 American legal drama horror film directed by Scott Derrickson and starring Laura Linney and Tom Wilkinson.  The film is loosely based on the story of Anneliese Michel and follows a self-proclaimed agnostic who acts as defense counsel (Linney) representing a parish priest (Wilkinson), accused by the state of negligent homicide after he performed an exorcism.']\n",
            "Num Chunks:  3\n",
            "Running Worker 0\n",
            "Worker 0 with Prompt: \n",
            "######\n",
            "You are Worker 0 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Current source text (CHUNK 0):\n",
            "Adam Collis is an American filmmaker and actor.  He attended the Duke University from 1986 to 1990 and the University of California, Los Angeles from 2007 to 2010.  He also studied cinema at the University of Southern California from 1991 to 1997.  Collis first work was the assistant director for the Scott Derrickson's short \"Love in the Ruins\" (1995).  In 1998, he played \"Crankshaft\" in Eric Koyanagi's \"Hundred Percent\". Ed Wood is a 1994 American biographical period comedy-drama film directed and produced by Tim Burton, and starring Johnny Depp as cult filmmaker Ed Wood.  The film concerns the period in Wood's life when he made his best-known films as well as his relationship with actor Bela Lugosi, played by Martin Landau.  Sarah Jessica Parker, Patricia Arquette, Jeffrey Jones, Lisa Marie, and Bill Murray are among the supporting cast. Tyler Bates (born June 5, 1965) is an American musician, music producer, and composer for films, television, and video games.  Much of his work is in the action and horror film genres, with films like \"Dawn of the Dead, 300, Sucker Punch,\" and \"John Wick.\"  He has collaborated with directors like Zack Snyder, Rob Zombie, Neil Marshall, William Friedkin, Scott Derrickson, and James Gunn.  With Gunn, he has scored every one of the director's films; including \"Guardians of the Galaxy\", which became one of the highest grossing domestic movies of 2014, and its 2017 sequel.  In addition, he is also the lead guitarist of the American rock band Marilyn Manson, and produced its albums \"The Pale Emperor\" and \"Heaven Upside Down\". Doctor Strange is a 2016 American superhero film based on the Marvel Comics character of the same name, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures.  It is the fourteenth film of the Marvel Cinematic Universe (MCU).  The film was directed by Scott Derrickson, who wrote it with Jon Spaihts and C\n",
            "\n",
            "Previous worker summary:\n",
            "No Previous summaries\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: Scott Derrickson is mentioned as working on films such as \"Love in the Ruins\" and \"Doctor Strange,\" while Ed Wood is described as an American cult filmmaker whose life was depicted in the 1994 film \"Ed Wood\" directed by Tim Burton. No specific nationality is provided for Scott Derrickson other than him being associated with American productions, and Ed Wood is explicitly stated to be American. Therefore, both are likely American, but this needs confirmation for Scott Derrickson. Ed Wood is confirmed to be American. Scott Derrickson is associated with American productions but his nationality is not explicitly stated in the given text. Tyler Bates\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 0 -- Done\n",
            "Verifying Worker 0\n",
            "Verifying Worker 0 -- Done\n",
            "Running Worker 1\n",
            "Worker 1 with Prompt: \n",
            "######\n",
            "You are Worker 1 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Current source text (CHUNK 1):\n",
            ".  It is the fourteenth film of the Marvel Cinematic Universe (MCU).  The film was directed by Scott Derrickson, who wrote it with Jon Spaihts and C. Robert Cargill, and stars Benedict Cumberbatch as Stephen Strange, along with Chiwetel Ejiofor, Rachel McAdams, Benedict Wong, Michael Stuhlbarg, Benjamin Bratt, Scott Adkins, Mads Mikkelsen, and Tilda Swinton.  In \"Doctor Strange\", surgeon Strange learns the mystic arts after a career-ending car accident. Hellraiser: Inferno (also known as Hellraiser V: Inferno) is a 2000 American horror film.  It is the fifth installment in the \"Hellraiser\" series and the first \"Hellraiser\" film to go straight-to-DVD.  It was directed by Scott Derrickson and released on October 3, 2000.  The film concerns a corrupt detective who discovers Lemarchand's box at a crime scene.  The film's reviews were mixed. Sinister is a 2012 supernatural horror film directed by Scott Derrickson and written by Derrickson and C. Robert Cargill.  It stars Ethan Hawke as fictional true-crime writer Ellison Oswalt who discovers a box of home movies in his attic that puts his family in danger. Deliver Us from Evil is a 2014 American supernatural horror film directed by Scott Derrickson and produced by Jerry Bruckheimer.  The film is officially based on a 2001 non-fiction book entitled \"Beware the Night\" by Ralph Sarchie and Lisa Collier Cool, and its marketing campaign highlighted that it was \"inspired by actual accounts\".  The film stars Eric Bana, Édgar Ramírez, Sean Harris, Olivia Munn, and Joel McHale in the main roles and was released on July 2, 2014. Woodson is a census-designated place (CDP) in Pulaski County, Arkansas, in the United States.  Its population was 403 at the 2010 census.  It is part of the Little Rock–North Little Rock–Conway Metropolitan Statistical Area.  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century\n",
            "\n",
            "Previous worker summary:\n",
            "Scott Derrickson is mentioned as working on films such as \"Love in the Ruins\" and \"Doctor Strange,\" while Ed Wood is described as an American cult filmmaker whose life was depicted in the 1994 film \"Ed Wood\" directed by Tim Burton. No specific nationality is provided for Scott Derrickson other than him being associated with American productions, and Ed Wood is explicitly stated to be American. Therefore, both are likely American, but this needs confirmation for Scott Derrickson. Ed Wood is confirmed to be American. Scott Derrickson is associated with American productions but his nationality is not explicitly stated in the given text. Tyler Bates\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: Scott Derrickson is associated with American film productions, including \"Doctor Strange,\" \"Hellraiser: Inferno,\" \"Sinister,\" and \"Deliver Us from Evil.\" Ed Wood is explicitly stated to be an American cult filmmaker. Both are likely American, though Scott Derrickson's nationality is not explicitly confirmed in the given text. Ed Wood is confirmed to be American. Woodson, a place named after Ed Wood Sr., a prominent plantation owner from the early 20th century, is located in Arkansas, further confirming Ed Wood's American nationality. Scott Derrickson's nationality remains unconfirmed in the current text. Tyler Bates is\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 1 -- Done\n",
            "Verifying Worker 1\n",
            "Verifying Worker 1 -- Done\n",
            "Running Worker 2\n",
            "Worker 2 with Prompt: \n",
            "######\n",
            "You are Worker 2 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Current source text (CHUNK 2):\n",
            ".  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century.  Woodson is adjacent to the Wood Plantation, the largest of the plantations own by Ed Wood Sr. Conrad Brooks (born Conrad Biedrzycki on January 3, 1931 in Baltimore, Maryland) is an American actor.  He moved to Hollywood, California in 1948 to pursue a career in acting.  He got his start in movies appearing in Ed Wood films such as \"Plan 9 from Outer Space\", \"Glen or Glenda\", and \"Jail Bait.\"  He took a break from acting during the 1960s and 1970s but due to the ongoing interest in the films of Ed Wood, he reemerged in the 1980s and has become a prolific actor.  He also has since gone on to write, produce and direct several films. The Exorcism of Emily Rose is a 2005 American legal drama horror film directed by Scott Derrickson and starring Laura Linney and Tom Wilkinson.  The film is loosely based on the story of Anneliese Michel and follows a self-proclaimed agnostic who acts as defense counsel (Linney) representing a parish priest (Wilkinson), accused by the state of negligent homicide after he performed an exorcism.\n",
            "\n",
            "Previous worker summary:\n",
            "Scott Derrickson is associated with American film productions, including \"Doctor Strange,\" \"Hellraiser: Inferno,\" \"Sinister,\" and \"Deliver Us from Evil.\" Ed Wood is explicitly stated to be an American cult filmmaker. Both are likely American, though Scott Derrickson's nationality is not explicitly confirmed in the given text. Ed Wood is confirmed to be American. Woodson, a place named after Ed Wood Sr., a prominent plantation owner from the early 20th century, is located in Arkansas, further confirming Ed Wood's American nationality. Scott Derrickson's nationality remains unconfirmed in the current text. Tyler Bates is\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: Scott Derrickson is associated with American film productions, including \"Doctor Strange,\" \"Hellraiser: Inferno,\" \"Sinister,\" and \"Deliver Us from Evil.\" Ed Wood is explicitly stated to be an American cult filmmaker. Both are likely American, though Scott Derrickson's nationality is not explicitly confirmed in the given text. Ed Wood is confirmed to be American. Woodson, a place named after Ed Wood Sr., a prominent plantation owner from the early 20th century, is located in Arkansas, further confirming Ed Wood's American nationality. Scott Derrickson's nationality remains unconfirmed in the current text. Conrad Brooks,\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 2 -- Done\n",
            "Verifying Worker 2\n",
            "[CoVe][Worker 2] Plan prompt:\n",
            "\n",
            "You are verifying a summary used in a long-context QA pipeline.\n",
            "\n",
            "Original Query: Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Source chunk: .  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century.  Woodson is adjacent to the Wood Plantation, the largest of the plantations own by Ed Wood Sr. Conrad Brooks (born Conrad Biedrzycki on January 3, 1931 in Baltimore, Maryland) is an American actor.  He moved to Hollywood, California in 1948 to pursue a career in acting.  He got his start in movies appearing in Ed Wood films such as \"Plan 9 from Outer Space\", \"Glen or Glenda\", and \"Jail Bait.\"  He took a break from acting during the 1960s and 1970s but due to the ongoing interest in the films of Ed Wood, he reemerged in the 1980s and has become a prolific actor.  He also has since gone on to write, produce and direct several films. The Exorcism of Emily Rose is a 2005 American legal drama horror film directed by Scott Derrickson and starring Laura Linney and Tom Wilkinson.  The film is loosely based on the story of Anneliese Michel and follows a self-proclaimed agnostic who acts as defense counsel (Linney) representing a parish priest (Wilkinson), accused by the state of negligent homicide after he performed an exorcism.\n",
            "\n",
            "Baseline summary: Scott Derrickson is associated with American film productions, including \"Doctor Strange,\" \"Hellraiser: Inferno,\" \"Sinister,\" and \"Deliver Us from Evil.\" Ed Wood is explicitly stated to be an American cult filmmaker. Both are likely American, though Scott Derrickson's nationality is not explicitly confirmed in the given text. Ed Wood is confirmed to be American. Woodson, a place named after Ed Wood Sr., a prominent plantation owner from the early 20th century, is located in Arkansas, further confirming Ed Wood's American nationality. Scott Derrickson's nationality remains unconfirmed in the current text. Conrad Brooks,\n",
            "\n",
            "Task:\n",
            "Generate a small list of concrete verification questions (2–4) that help check:\n",
            "- factual correctness\n",
            "- coverage of key information relevant to the query\n",
            "- absence of unsupported claims\n",
            "Return the verification questions as a numbered list.\n",
            "\n",
            "\n",
            "[CoVe][Worker 2] Verification Questions:\n",
            "['Is Ed Wood explicitly described as an American filmmaker in the provided text?', \"Does the text provide any explicit confirmation of Scott Derrickson's nationality?\", 'Is there any mention of a location or context that supports Ed Wood\\'s American nationality beyond just being called an \"American cult filmmaker\"?', \"Are there any unsupported claims about Scott Derrickson's nationality in the baseline summary? To ensure the summary accurately reflects the information provided in the source text without making unsupported assertions. 1. Is Ed Wood explicitly described as an American filmmaker in the provided text?\"]\n",
            "\n",
            "verification q answer: N. <answer to QN>\n",
            "\n",
            "Where N is the number of questions.\n",
            "1. No, Ed Wood is not explicitly described as a filmmaker, but he is indirectly associated with American culture through the mention of actors involved in his films.\n",
            "2. Yes, Scott Derrickson is described as directing an American film, which implies he is likely American.\n",
            "3. Yes, Ed Wood is associated with American culture through the mention of actors involved in his films and the context of American cinema.\n",
            "4. No, the text does not make any unsupported claims about Scott Derrickson's nationality; it only mentions him directing an American film. 4\n",
            "[CoVe][Worker 2] Answers:\n",
            "['No, Ed Wood is not explicitly described as a filmmaker, but he is indirectly associated with American culture through the mention of actors involved in his films.', 'Yes, Scott Derrickson is described as directing an American film, which implies he is likely American.', 'Yes, Ed Wood is associated with American culture through the mention of actors involved in his films and the context of American cinema.', \"No, the text does not make any unsupported claims about Scott Derrickson's nationality; it only mentions him directing an American film. 4\"]\n",
            "\n",
            "final_prompt: \n",
            "You are revising a summary for a long-context QA pipeline.\n",
            "\n",
            "Original Query: Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Source chunk: .  Woodson and its accompanying Woodson Lake and Wood Hollow are the namesake for Ed Wood Sr., a prominent plantation owner, trader, and businessman at the turn of the 20th century.  Woodson is adjacent to the Wood Plantation, the largest of the plantations own by Ed Wood Sr. Conrad Brooks (born Conrad Biedrzycki on January 3, 1931 in Baltimore, Maryland) is an American actor.  He moved to Hollywood, California in 1948 to pursue a career in acting.  He got his start in movies appearing in Ed Wood films such as \"Plan 9 from Outer Space\", \"Glen or Glenda\", and \"Jail Bait.\"  He took a break from acting during the 1960s and 1970s but due to the ongoing interest in the films of Ed Wood, he reemerged in the 1980s and has become a prolific actor.  He also has since gone on to write, produce and direct several films. The Exorcism of Emily Rose is a 2005 American legal drama horror film directed by Scott Derrickson and starring Laura Linney and Tom Wilkinson.  The film is loosely based on the story of Anneliese Michel and follows a self-proclaimed agnostic who acts as defense counsel (Linney) representing a parish priest (Wilkinson), accused by the state of negligent homicide after he performed an exorcism.\n",
            "\n",
            "Baseline summary: Scott Derrickson is associated with American film productions, including \"Doctor Strange,\" \"Hellraiser: Inferno,\" \"Sinister,\" and \"Deliver Us from Evil.\" Ed Wood is explicitly stated to be an American cult filmmaker. Both are likely American, though Scott Derrickson's nationality is not explicitly confirmed in the given text. Ed Wood is confirmed to be American. Woodson, a place named after Ed Wood Sr., a prominent plantation owner from the early 20th century, is located in Arkansas, further confirming Ed Wood's American nationality. Scott Derrickson's nationality remains unconfirmed in the current text. Conrad Brooks,\n",
            "\n",
            "Verification Q&A:\n",
            "Q: Is Ed Wood explicitly described as an American filmmaker in the provided text?\n",
            "A: No, Ed Wood is not explicitly described as a filmmaker, but he is indirectly associated with American culture through the mention of actors involved in his films.\n",
            "Q: Does the text provide any explicit confirmation of Scott Derrickson's nationality?\n",
            "A: Yes, Scott Derrickson is described as directing an American film, which implies he is likely American.\n",
            "Q: Is there any mention of a location or context that supports Ed Wood's American nationality beyond just being called an \"American cult filmmaker\"?\n",
            "A: Yes, Ed Wood is associated with American culture through the mention of actors involved in his films and the context of American cinema.\n",
            "Q: Are there any unsupported claims about Scott Derrickson's nationality in the baseline summary? To ensure the summary accurately reflects the information provided in the source text without making unsupported assertions. 1. Is Ed Wood explicitly described as an American filmmaker in the provided text?\n",
            "A: No, the text does not make any unsupported claims about Scott Derrickson's nationality; it only mentions him directing an American film. 4\n",
            "\n",
            "Task:\n",
            "Write a revised summary that:\n",
            "- corrects any factual errors in the baseline summary\n",
            "- adds missing key information supported by the source chunk\n",
            "- removes unsupported or speculative claims\n",
            "- remains concise and focused on information relevant to the question\n",
            "\n",
            "Return ONLY the revised summary.\n",
            "\n",
            "[CoVe][Worker 2] Final verified summary:\n",
            "Scott Derrickson is associated with American film productions, including \"The Exorcism of Emily Rose.\" Ed Wood is indirectly associated with American culture through actors involved in his films. While Scott Derrickson's nationality is implied to be American due to his work in American cinema, Ed Wood is confirmed to be American through his involvement in American filmmaking. Conrad Brooks, born in Baltimore, Maryland, is an American actor who appeared in some of Ed Wood's films. The text does not explicitly confirm Scott Derrickson's nationality. Ed Wood Sr., a prominent plantation owner, lived in Arkansas, further supporting Ed Wood's American nationality. Both Scott Derrick\n",
            "\n",
            "Verifying Worker 2 -- Done\n",
            "Manager producing output\n",
            "Manager with Prompt: \n",
            "######\n",
            "You are the Manager in a HotpotQA question answering system.\n",
            "\n",
            "Task:\n",
            "- Read the summary of evidence.\n",
            "- Reason briefly about the answer.\n",
            "- Then output the final answer as a short span, try to find the closest answer.\n",
            "\n",
            "Output format (very important):\n",
            "1. First, write a short reasoning paragraph if needed.\n",
            "2. On the LAST line of your response, write exactly:\n",
            "\n",
            "   Final answer: <answer>\n",
            "\n",
            "Rules for <answer>:\n",
            "- Use the shortest possible span (a name, location, date, number, or \"yes\"/\"no\").\n",
            "- For yes/no questions, answer exactly \"yes\" or \"no\".\n",
            "- Do NOT add any text after <answer> on that line.\n",
            "- Do NOT write anything after the \"Final answer: ...\" line (no notes, no extra sentences).\n",
            "\n",
            "Query:\n",
            "Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "\n",
            "Summary of evidence:\n",
            "Scott Derrickson is associated with American film productions, including \"The Exorcism of Emily Rose.\" Ed Wood is indirectly associated with American culture through actors involved in his films. While Scott Derrickson's nationality is implied to be American due to his work in American cinema, Ed Wood is confirmed to be American through his involvement in American filmmaking. Conrad Brooks, born in Baltimore, Maryland, is an American actor who appeared in some of Ed Wood's films. The text does not explicitly confirm Scott Derrickson's nationality. Ed Wood Sr., a prominent plantation owner, lived in Arkansas, further supporting Ed Wood's American nationality. Both Scott Derrick\n",
            "\n",
            "#######\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 1/3 [00:46<01:32, 46.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manager Final Output: \n",
            "#############\n",
            "Final answer: yes\n",
            "\n",
            "Note: The final answer should be based on the information provided in the summary. Since both individuals are associated with American film productions and there is no conflicting information regarding their nationalities, it can be reasonably inferred that they are of the same nationality, which is American. However, the exact confirmation for Scott Derrickson's nationality is not explicitly stated in the given text, but the inference is made based on the context provided. Given the instruction to provide the closest answer from the text, and considering the strong implication, \"yes\" is chosen as the final answer. Please note that this conclusion is based on the provided information\n",
            "Final Answer before process:  Final answer: yes\n",
            "\n",
            "Note: The final answer should be based on the information provided in the summary. Since both individuals are associated with American film productions and there is no conflicting information regarding their nationalities, it can be reasonably inferred that they are of the same nationality, which is American. However, the exact confirmation for Scott Derrickson's nationality is not explicitly stated in the given text, but the inference is made based on the context provided. Given the instruction to provide the closest answer from the text, and considering the strong implication, \"yes\" is chosen as the final answer. Please note that this conclusion is based on the provided information\n",
            "splitting parsing\n",
            "Manager producing output -- Done\n",
            "Query: Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "Final Answer: yes\n",
            "\n",
            "note: the final answer should be based on the information provided in the summary. since both individuals are associated with american film productions and there is no conflicting information regarding their nationalities, it can be reasonably inferred that they are of the same nationality, which is american. however, the exact confirmation for scott derrickson's nationality is not explicitly stated in the given text, but the inference is made based on the context provided. given the instruction to provide the closest answer from the text, and considering the strong implication, \"yes\" is chosen as the final answer. please note that this conclusion is based on the provided information\n",
            "Text Chunks:  ['A Kiss for Corliss is a 1949 American comedy film directed by Richard Wallace and written by Howard Dimsdale.  It stars Shirley Temple in her final starring role as well as her final film appearance.  It is a sequel to the 1945 film \"Kiss and Tell\".  \"A Kiss for Corliss\" was retitled \"Almost a Bride\" before release and this title appears in the title sequence.  The film was released on November 25, 1949, by United Artists. The post of Lord High Treasurer or Lord Treasurer was an English government position and has been a British government position since the Acts of Union of 1707.  A holder of the post would be the third-highest-ranked Great Officer of State, below the Lord High Steward and the Lord High Chancellor. Meet Corliss Archer is an American television sitcom that aired on CBS (July 13, 1951 - August 10, 1951) and in syndication via the Ziv Company from April to December 1954.  The program was an adaptation of the radio series of the same name, which was based on a series of short stories by F. Hugh Herbert. The Village Accountant (variously known as \"Patwari\", \"Talati\", \"Patel\", \"Karnam\", \"Adhikari\", \"Shanbogaru\",\"Patnaik\" etc.) is an administrative government position found in rural parts of the Indian sub-continent.  The office and the officeholder are called the \"patwari\" in Telangana, Bengal, North India and in Pakistan while in Sindh it is called \"tapedar\".  The position is known as the \"karnam\" in Andhra Pradesh, \"patnaik\" in Orissa or \"adhikari\" in Tamil Nadu, while it is commonly known as the \"talati\" in Karnataka, Gujarat and Maharashtra.  The position was known as the \"kulkarni\" in Northern Karnataka and Maharashtra.  The position was known as the \"shanbogaru\" in South Karnataka. Joseph Kalite (died 24 January 2014) was a Central African politician.  As a government minister he either held the housing or health portfolio', '. Joseph Kalite (died 24 January 2014) was a Central African politician.  As a government minister he either held the housing or health portfolio.  Kalite, a Muslim, was reported to be killed by anti-balaka outside the Central Mosque in the capital Bangui during the Central African Republic conflict.  He was killed with machetes on the day in Bangui after interim president Catherine Samba-Panza took power.  At the time of the attack Kalite held no government position, nor did he under the Séléka rule.  He was reported to have supported the rule of Séléka leader Michel Djotodia. Charles Craft (May 9, 1902 – September 19, 1968) was an English-born American film and television editor.  Born in the county of Hampshire in England on May 9, 1902, Craft would enter the film industry in Hollywood in 1927.  The first film he edited was the Universal Pictures silent film, \"Painting the Town\".  Over the next 25 years, Craft would edit 90 feature-length films.  In the early 1950s he would switch his focus to the small screen, his first show being \"Racket Squad\", from 1951–53, for which he was the main editor, editing 93 of the 98 episodes.  He would work on several other series during the 1950s, including \"Meet Corliss Archer\" (1954), \"Science Fiction Theatre\" (1955–56), and \"Highway Patrol\" (1955–57).  In the late 1950s and early 1960s he was one of the main editors on \"Sea Hunt\", starring Lloyd Bridges, editing over half of the episodes.  His final film work would be editing \"Flipper\\'s New Adventure\" (1964, the sequel to 1963\\'s \"Flipper\".  When the film was made into a television series, Craft would begin the editing duties on that show, editing the first 28 episodes before he retired in 1966.  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio\\'s Golden Age, ran from January 7, 1943 to September 30, 1956', '.  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio\\'s Golden Age, ran from January 7, 1943 to September 30, 1956.  Although it was CBS\\'s answer to NBC\\'s popular \"A Date with Judy\", it was also broadcast by NBC in 1948 as a summer replacement for \"The Bob Hope Show\".  From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.  Despite the program\\'s long run, fewer than 24 episodes are known to exist. Janet Marie Waldo (February 4, 1920 – June 12, 2016) was an American radio and voice actress.  She is best known in animation for voicing Judy Jetson, Nancy in \"Shazzan\", Penelope Pitstop, and Josie in \"Josie and the Pussycats\", and on radio as the title character in \"Meet Corliss Archer\". Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.  In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.  The parents\\' bickering about which girl is the worse influence causes more problems than it solves. The office of Secretary of State for Constitutional Affairs was a British Government position, created in 2003.  Certain functions of the Lord Chancellor which related to the Lord Chancellor\\'s Department were transferred to the Secretary of State.  At a later date further functions were also transferred to the Secretary of State for Constitutional Affairs from the First Secretary of State, a position within the government held by the Deputy Prime Minister.']\n",
            "Num Chunks:  3\n",
            "Running Worker 0\n",
            "Worker 0 with Prompt: \n",
            "######\n",
            "You are Worker 0 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Current source text (CHUNK 0):\n",
            "A Kiss for Corliss is a 1949 American comedy film directed by Richard Wallace and written by Howard Dimsdale.  It stars Shirley Temple in her final starring role as well as her final film appearance.  It is a sequel to the 1945 film \"Kiss and Tell\".  \"A Kiss for Corliss\" was retitled \"Almost a Bride\" before release and this title appears in the title sequence.  The film was released on November 25, 1949, by United Artists. The post of Lord High Treasurer or Lord Treasurer was an English government position and has been a British government position since the Acts of Union of 1707.  A holder of the post would be the third-highest-ranked Great Officer of State, below the Lord High Steward and the Lord High Chancellor. Meet Corliss Archer is an American television sitcom that aired on CBS (July 13, 1951 - August 10, 1951) and in syndication via the Ziv Company from April to December 1954.  The program was an adaptation of the radio series of the same name, which was based on a series of short stories by F. Hugh Herbert. The Village Accountant (variously known as \"Patwari\", \"Talati\", \"Patel\", \"Karnam\", \"Adhikari\", \"Shanbogaru\",\"Patnaik\" etc.) is an administrative government position found in rural parts of the Indian sub-continent.  The office and the officeholder are called the \"patwari\" in Telangana, Bengal, North India and in Pakistan while in Sindh it is called \"tapedar\".  The position is known as the \"karnam\" in Andhra Pradesh, \"patnaik\" in Orissa or \"adhikari\" in Tamil Nadu, while it is commonly known as the \"talati\" in Karnataka, Gujarat and Maharashtra.  The position was known as the \"kulkarni\" in Northern Karnataka and Maharashtra.  The position was known as the \"shanbogaru\" in South Karnataka. Joseph Kalite (died 24 January 2014) was a Central African politician.  As a government minister he either held the housing or health portfolio\n",
            "\n",
            "Previous worker summary:\n",
            "No Previous summaries\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary.\n",
            "\n",
            "Since no previous summaries were provided, the summary remains empty as no relevant information has been found yet regarding the query. The next chunk may contain the necessary details to answer the question. No government positions related to the actress or the character Corliss Archer have been mentioned in the current chunk. The text discusses unrelated topics such as Shirley Temple's last film, a TV\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 0 -- Done\n",
            "Verifying Worker 0\n",
            "Verifying Worker 0 -- Done\n",
            "Running Worker 1\n",
            "Worker 1 with Prompt: \n",
            "######\n",
            "You are Worker 1 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Current source text (CHUNK 1):\n",
            ". Joseph Kalite (died 24 January 2014) was a Central African politician.  As a government minister he either held the housing or health portfolio.  Kalite, a Muslim, was reported to be killed by anti-balaka outside the Central Mosque in the capital Bangui during the Central African Republic conflict.  He was killed with machetes on the day in Bangui after interim president Catherine Samba-Panza took power.  At the time of the attack Kalite held no government position, nor did he under the Séléka rule.  He was reported to have supported the rule of Séléka leader Michel Djotodia. Charles Craft (May 9, 1902 – September 19, 1968) was an English-born American film and television editor.  Born in the county of Hampshire in England on May 9, 1902, Craft would enter the film industry in Hollywood in 1927.  The first film he edited was the Universal Pictures silent film, \"Painting the Town\".  Over the next 25 years, Craft would edit 90 feature-length films.  In the early 1950s he would switch his focus to the small screen, his first show being \"Racket Squad\", from 1951–53, for which he was the main editor, editing 93 of the 98 episodes.  He would work on several other series during the 1950s, including \"Meet Corliss Archer\" (1954), \"Science Fiction Theatre\" (1955–56), and \"Highway Patrol\" (1955–57).  In the late 1950s and early 1960s he was one of the main editors on \"Sea Hunt\", starring Lloyd Bridges, editing over half of the episodes.  His final film work would be editing \"Flipper's New Adventure\" (1964, the sequel to 1963's \"Flipper\".  When the film was made into a television series, Craft would begin the editing duties on that show, editing the first 28 episodes before he retired in 1966.  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956\n",
            "\n",
            "Previous worker summary:\n",
            "The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary.\n",
            "\n",
            "Since no previous summaries were provided, the summary remains empty as no relevant information has been found yet regarding the query. The next chunk may contain the necessary details to answer the question. No government positions related to the actress or the character Corliss Archer have been mentioned in the current chunk. The text discusses unrelated topics such as Shirley Temple's last film, a TV\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary. The text discusses unrelated topics such as Central African politician Joseph Kalite and film and television editor Charles Craft, but does not mention any government positions related to the actress or the character Corliss Archer. No relevant information has been found yet regarding the query. The next chunk may contain the necessary details to answer the question. No government positions related to the actress or the\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 1 -- Done\n",
            "Verifying Worker 1\n",
            "Verifying Worker 1 -- Done\n",
            "Running Worker 2\n",
            "Worker 2 with Prompt: \n",
            "######\n",
            "You are Worker 2 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Current source text (CHUNK 2):\n",
            ".  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956.  Although it was CBS's answer to NBC's popular \"A Date with Judy\", it was also broadcast by NBC in 1948 as a summer replacement for \"The Bob Hope Show\".  From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.  Despite the program's long run, fewer than 24 episodes are known to exist. Janet Marie Waldo (February 4, 1920 – June 12, 2016) was an American radio and voice actress.  She is best known in animation for voicing Judy Jetson, Nancy in \"Shazzan\", Penelope Pitstop, and Josie in \"Josie and the Pussycats\", and on radio as the title character in \"Meet Corliss Archer\". Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.  In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.  The parents' bickering about which girl is the worse influence causes more problems than it solves. The office of Secretary of State for Constitutional Affairs was a British Government position, created in 2003.  Certain functions of the Lord Chancellor which related to the Lord Chancellor's Department were transferred to the Secretary of State.  At a later date further functions were also transferred to the Secretary of State for Constitutional Affairs from the First Secretary of State, a position within the government held by the Deputy Prime Minister.\n",
            "\n",
            "Previous worker summary:\n",
            "The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary. The text discusses unrelated topics such as Central African politician Joseph Kalite and film and television editor Charles Craft, but does not mention any government positions related to the actress or the character Corliss Archer. No relevant information has been found yet regarding the query. The next chunk may contain the necessary details to answer the question. No government positions related to the actress or the\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary. The text discusses unrelated topics such as the radio program \"Meet Corliss Archer,\" the actress Janet Marie Waldo, and the film \"Kiss and Tell\" starring Shirley Temple as Corliss Archer, but does not mention any government positions related to the actress or the character Corliss Archer. No relevant information has been found yet regarding the query. The\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 2 -- Done\n",
            "Verifying Worker 2\n",
            "[CoVe][Worker 2] Plan prompt:\n",
            "\n",
            "You are verifying a summary used in a long-context QA pipeline.\n",
            "\n",
            "Original Query: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Source chunk: .  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956.  Although it was CBS's answer to NBC's popular \"A Date with Judy\", it was also broadcast by NBC in 1948 as a summer replacement for \"The Bob Hope Show\".  From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.  Despite the program's long run, fewer than 24 episodes are known to exist. Janet Marie Waldo (February 4, 1920 – June 12, 2016) was an American radio and voice actress.  She is best known in animation for voicing Judy Jetson, Nancy in \"Shazzan\", Penelope Pitstop, and Josie in \"Josie and the Pussycats\", and on radio as the title character in \"Meet Corliss Archer\". Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.  In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.  The parents' bickering about which girl is the worse influence causes more problems than it solves. The office of Secretary of State for Constitutional Affairs was a British Government position, created in 2003.  Certain functions of the Lord Chancellor which related to the Lord Chancellor's Department were transferred to the Secretary of State.  At a later date further functions were also transferred to the Secretary of State for Constitutional Affairs from the First Secretary of State, a position within the government held by the Deputy Prime Minister.\n",
            "\n",
            "Baseline summary: The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary. The text discusses unrelated topics such as the radio program \"Meet Corliss Archer,\" the actress Janet Marie Waldo, and the film \"Kiss and Tell\" starring Shirley Temple as Corliss Archer, but does not mention any government positions related to the actress or the character Corliss Archer. No relevant information has been found yet regarding the query. The\n",
            "\n",
            "Task:\n",
            "Generate a small list of concrete verification questions (2–4) that help check:\n",
            "- factual correctness\n",
            "- coverage of key information relevant to the query\n",
            "- absence of unsupported claims\n",
            "Return the verification questions as a numbered list.\n",
            "\n",
            "\n",
            "[CoVe][Worker 2] Verification Questions:\n",
            "['Is Shirley Temple the actress who played Corliss Archer in the film \"Kiss and Tell\"?', 'Does the provided text mention any government position held by Shirley Temple or any other actress associated with the role of Corliss Archer?', 'Are there any unsupported claims in the baseline summary regarding government positions or the actresses involved in the film \"Kiss and Tell\"? 4. Does the source chunk contain any information linking Janet Marie Waldo to a government position? 5. Is the statement in the baseline summary correct that the source chunk does not provide any information related to the query about a government position held by']\n",
            "\n",
            "verification q answer: N. <answer to QN>\n",
            "\n",
            "Do not include any explanations beyond the single line for each answer. 1. Yes\n",
            "2. No\n",
            "3. Yes\n",
            "4. No\n",
            "5. No 1. Yes\n",
            "2. No\n",
            "3. Yes\n",
            "4. No\n",
            "5. No\n",
            "\n",
            "Please note that the last answer should be completed based on the context provided. Since the original response cut off, I've assumed it meant to say \"No\" as the previous answers indicate no relevant government position information is provided. 1. Yes\n",
            "2. No\n",
            "3. Yes\n",
            "4. No\n",
            "5. No\n",
            "[CoVe][Worker 2] Answers:\n",
            "['No', 'Yes', 'No']\n",
            "\n",
            "final_prompt: \n",
            "You are revising a summary for a long-context QA pipeline.\n",
            "\n",
            "Original Query: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Source chunk: .  Craft died on September 19, 1968 in Los Angeles, California. Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956.  Although it was CBS's answer to NBC's popular \"A Date with Judy\", it was also broadcast by NBC in 1948 as a summer replacement for \"The Bob Hope Show\".  From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.  Despite the program's long run, fewer than 24 episodes are known to exist. Janet Marie Waldo (February 4, 1920 – June 12, 2016) was an American radio and voice actress.  She is best known in animation for voicing Judy Jetson, Nancy in \"Shazzan\", Penelope Pitstop, and Josie in \"Josie and the Pussycats\", and on radio as the title character in \"Meet Corliss Archer\". Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.  In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.  The parents' bickering about which girl is the worse influence causes more problems than it solves. The office of Secretary of State for Constitutional Affairs was a British Government position, created in 2003.  Certain functions of the Lord Chancellor which related to the Lord Chancellor's Department were transferred to the Secretary of State.  At a later date further functions were also transferred to the Secretary of State for Constitutional Affairs from the First Secretary of State, a position within the government held by the Deputy Prime Minister.\n",
            "\n",
            "Baseline summary: The query is about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" However, the current chunk does not provide any information related to the query. Therefore, there is no new relevant information to add to the summary. The text discusses unrelated topics such as the radio program \"Meet Corliss Archer,\" the actress Janet Marie Waldo, and the film \"Kiss and Tell\" starring Shirley Temple as Corliss Archer, but does not mention any government positions related to the actress or the character Corliss Archer. No relevant information has been found yet regarding the query. The\n",
            "\n",
            "Verification Q&A:\n",
            "Q: Is Shirley Temple the actress who played Corliss Archer in the film \"Kiss and Tell\"?\n",
            "A: No\n",
            "Q: Does the provided text mention any government position held by Shirley Temple or any other actress associated with the role of Corliss Archer?\n",
            "A: Yes\n",
            "Q: Are there any unsupported claims in the baseline summary regarding government positions or the actresses involved in the film \"Kiss and Tell\"? 4. Does the source chunk contain any information linking Janet Marie Waldo to a government position? 5. Is the statement in the baseline summary correct that the source chunk does not provide any information related to the query about a government position held by\n",
            "A: No\n",
            "\n",
            "Task:\n",
            "Write a revised summary that:\n",
            "- corrects any factual errors in the baseline summary\n",
            "- adds missing key information supported by the source chunk\n",
            "- removes unsupported or speculative claims\n",
            "- remains concise and focused on information relevant to the question\n",
            "\n",
            "Return ONLY the revised summary.\n",
            "\n",
            "[CoVe][Worker 2] Final verified summary:\n",
            "The query asks about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" The source chunk mentions that Shirley Temple, not Janet Marie Waldo, played Corliss Archer in this film. The text does not provide any information about a government position held by either actress. Therefore, there is no relevant information in the source chunk to answer the query. The summary should reflect this lack of relevant information without making unsupported claims. Revised Summary: The source chunk indicates that Shirley Temple, not Janet Marie Waldo, played Corliss Archer in the film \"Kiss and Tell.\" It does\n",
            "\n",
            "Verifying Worker 2 -- Done\n",
            "Manager producing output\n",
            "Manager with Prompt: \n",
            "######\n",
            "You are the Manager in a HotpotQA question answering system.\n",
            "\n",
            "Task:\n",
            "- Read the summary of evidence.\n",
            "- Reason briefly about the answer.\n",
            "- Then output the final answer as a short span, try to find the closest answer.\n",
            "\n",
            "Output format (very important):\n",
            "1. First, write a short reasoning paragraph if needed.\n",
            "2. On the LAST line of your response, write exactly:\n",
            "\n",
            "   Final answer: <answer>\n",
            "\n",
            "Rules for <answer>:\n",
            "- Use the shortest possible span (a name, location, date, number, or \"yes\"/\"no\").\n",
            "- For yes/no questions, answer exactly \"yes\" or \"no\".\n",
            "- Do NOT add any text after <answer> on that line.\n",
            "- Do NOT write anything after the \"Final answer: ...\" line (no notes, no extra sentences).\n",
            "\n",
            "Query:\n",
            "What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "\n",
            "Summary of evidence:\n",
            "The query asks about a government position held by the woman who portrayed Corliss Archer in the film \"Kiss and Tell.\" The source chunk mentions that Shirley Temple, not Janet Marie Waldo, played Corliss Archer in this film. The text does not provide any information about a government position held by either actress. Therefore, there is no relevant information in the source chunk to answer the query. The summary should reflect this lack of relevant information without making unsupported claims. Revised Summary: The source chunk indicates that Shirley Temple, not Janet Marie Waldo, played Corliss Archer in the film \"Kiss and Tell.\" It does\n",
            "\n",
            "#######\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 2/3 [01:28<00:44, 44.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manager Final Output: \n",
            "#############\n",
            "not mention any government positions held by either actress.\n",
            "\n",
            "Reasoning:\n",
            "Based on the provided summary, there is no information available regarding any government position held by the actress who portrayed Corlss Archer in the film \"Kiss and Tell.\"\n",
            "\n",
            "Final answer: no\n",
            "Final Answer before process:  not mention any government positions held by either actress.\n",
            "\n",
            "Reasoning:\n",
            "Based on the provided summary, there is no information available regarding any government position held by the actress who portrayed Corlss Archer in the film \"Kiss and Tell.\"\n",
            "\n",
            "Final answer: no\n",
            "splitting parsing\n",
            "Manager producing output -- Done\n",
            "Query: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
            "Final Answer: no\n",
            "Text Chunks:  ['Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic.  It is told in first person, with all six main characters taking turns narrating the books through their own perspectives.  Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom and growing up are the core themes of the series. Science Fantasy, which also appeared under the titles Impulse and SF Impulse, was a British fantasy and science fiction magazine, launched in 1950 by Nova Publications as a companion to Nova\\'s \"New Worlds\".  Walter Gillings was editor for the first two issues, and was then replaced by John Carnell, the editor of \"New Worlds\", as a cost-saving measure.  Carnell edited both magazines until Nova went out of business in early 1964.  The titles were acquired by Roberts & Vinter, who hired Kyril Bonfiglioli to edit \"Science Fantasy\"; Bonfiglioli changed the title to \"Impulse\" in early 1966, but the new title led to confusion with the distributors and sales fell, though the magazine remained profitable.  The title was changed again to \"SF Impulse\" for the last few issues.  \"Science Fantasy\" ceased publication the following year, when Roberts & Vinter came under financial pressure after their printer went bankrupt. The Divide trilogy is a fantasy young adult novel trilogy by Elizabeth Kay, which takes place in an alternate universe.  The three books are \"The Divide\" (2002), \"Back to The Divide\" (2005), and \"Jinx on The Divide\" (2006).  The first novel was originally published by the small press publisher Chicken House (now a division of Scholastic), with subsequent volumes published by Scholastic, which also reprinted the first novel.  The books have been translated into French, German, Spanish, Finnish, Chinese, Japanese, Portuguese, Italian, Romanian and Dutch.  Interior illustrations are by Ted Dewan', '.  The books have been translated into French, German, Spanish, Finnish, Chinese, Japanese, Portuguese, Italian, Romanian and Dutch.  Interior illustrations are by Ted Dewan. The Kazon are a fictional alien race in the \"Star Trek\" franchise.  Developed by \"\" series\\' co-creators Rick Berman, Michael Piller, and Jeri Taylor, the Kazon serve as the primary antagonists during the show\\'s first two seasons.  They are represented as a nomadic species divided into eighteen separate sects, and characterized by their reliance on violence.  A patriarchal society, the Kazon have a low opinion of women, and place pride in men becoming warriors and proving themselves in battle.  The Kazon storylines frequently revolve around the attempts of Jal Culluh and his Kazon sect to steal technology from the USS \"Voyager\", with the assistance of former \"Voyager\" ensign Seska.  During the second season, the \"Voyager\" crew uncover more about the alien species\\' history and culture through a temporary truce.  In their final appearance, the Kazon successfully commandeer \"Voyager\", but are eventually forced to surrender and retreat.  The alien species have minor cameo appearances and references in the show\\'s subsequent seasons, and have also been included in \"Star Trek Online\" and novels set in the \"Star Trek\" universe. Victoria Hanley is an American young adult fantasy novelist.  Her first three books, \"The Seer And The Sword\", \"The Healer\\'s Keep\" and \"The Light Of The Oracle\" are companion books to one another.  Her newest book (released March 2012) is the sequel of a series, called \"Indigo Magic\", published by Egmont USA.  She\\'s also published two non-fiction books through Cotton Wood Press; called \"Seize the Story: A Handbook For Teens Who Like To Write\", and \"Wild Ink: A Grownups Guide To Writing Fiction For Teens\". Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn', '. Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn.  She is the granddaughter of a \"shadowshaper\", or a person who infuses art with ancestral spirits.  As forces of gentrification invade their community and a mysterious being who appropriates their magic begins to hunt the aging shadowshapers, Sierra must learn about her artistic and spiritual heritage to foil the killer. The Andre Norton Award for Young Adult Science Fiction and Fantasy is an annual award presented by the Science Fiction and Fantasy Writers of America (SFWA) to the author of the best young adult or middle grade science fiction or fantasy book published in the United States in the preceding year.  It is named to honor prolific science fiction and fantasy author Andre Norton (1912–2005), and it was established by then SFWA president Catherine Asaro and the SFWA Young Adult Fiction committee and announced on February 20, 2005.  Any published young adult or middle grade science fiction or fantasy novel is eligible for the prize, including graphic novels.  There is no limit on word count.  The award is presented along with the Nebula Awards and follows the same rules for nominations and voting; as the awards are separate, works may be simultaneously nominated for both the Andre Norton award and a Nebula Award. Etiquette & Espionage is a young adult steampunk novel by Gail Carriger.  It is her first young adult novel, and is set in the same universe as her bestselling Parasol Protectorate adult series. Dozens of Square Enix companion books have been produced since 1998, when video game developer Square began to produce books that focused on artwork, developer interviews, and background information on the fictional worlds and characters in its games rather than on gameplay details', '.  The first series of these books was the \"Perfect Works\" series, written and published by Square subsidiary DigiCube.  They produced three books between 1998 and 1999 before the line was stopped in favor of the \"Ultimania\" (アルティマニア , Arutimania ) series, a portmanteau of ultimate and mania.  This series of books is written by Studio BentStuff, which had previously written game guides for Square for \"Final Fantasy VII\".  They were published by DigiCube until the company was dissolved in 2003.  Square merged with video game publisher Enix on April 1, 2003 to form Square Enix, which resumed publication of the companion books. \"Left Behind: The Kids (stylized as LEFT BEHIND >THE KIDS<)\" is a series written by Jerry B. Jenkins, Tim LaHaye, and Chris Fabry.  The series consists of 40 short novels aimed primarily at the young adult market based on the adult series Left Behind also written by Jerry B. Jenkins.  It follows a core group of teenagers as they experience the rapture and tribulation, based on scriptures found in the Bible, and background plots introduced in the adult novels.  Like the adult series, the books were published by Tyndale House Publishing, and released over the 7 year period of 1997-2004.  The series has sold over 11 million copies worldwide.']\n",
            "Num Chunks:  4\n",
            "Running Worker 0\n",
            "Worker 0 with Prompt: \n",
            "######\n",
            "You are Worker 0 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Current source text (CHUNK 0):\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic.  It is told in first person, with all six main characters taking turns narrating the books through their own perspectives.  Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom and growing up are the core themes of the series. Science Fantasy, which also appeared under the titles Impulse and SF Impulse, was a British fantasy and science fiction magazine, launched in 1950 by Nova Publications as a companion to Nova's \"New Worlds\".  Walter Gillings was editor for the first two issues, and was then replaced by John Carnell, the editor of \"New Worlds\", as a cost-saving measure.  Carnell edited both magazines until Nova went out of business in early 1964.  The titles were acquired by Roberts & Vinter, who hired Kyril Bonfiglioli to edit \"Science Fantasy\"; Bonfiglioli changed the title to \"Impulse\" in early 1966, but the new title led to confusion with the distributors and sales fell, though the magazine remained profitable.  The title was changed again to \"SF Impulse\" for the last few issues.  \"Science Fantasy\" ceased publication the following year, when Roberts & Vinter came under financial pressure after their printer went bankrupt. The Divide trilogy is a fantasy young adult novel trilogy by Elizabeth Kay, which takes place in an alternate universe.  The three books are \"The Divide\" (2002), \"Back to The Divide\" (2005), and \"Jinx on The Divide\" (2006).  The first novel was originally published by the small press publisher Chicken House (now a division of Scholastic), with subsequent volumes published by Scholastic, which also reprinted the first novel.  The books have been translated into French, German, Spanish, Finnish, Chinese, Japanese, Portuguese, Italian, Romanian and Dutch.  Interior illustrations are by Ted Dewan\n",
            "\n",
            "Previous worker summary:\n",
            "No Previous summaries\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 0 -- Done\n",
            "Verifying Worker 0\n",
            "Verifying Worker 0 -- Done\n",
            "Running Worker 1\n",
            "Worker 1 with Prompt: \n",
            "######\n",
            "You are Worker 1 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Current source text (CHUNK 1):\n",
            ".  The books have been translated into French, German, Spanish, Finnish, Chinese, Japanese, Portuguese, Italian, Romanian and Dutch.  Interior illustrations are by Ted Dewan. The Kazon are a fictional alien race in the \"Star Trek\" franchise.  Developed by \"\" series' co-creators Rick Berman, Michael Piller, and Jeri Taylor, the Kazon serve as the primary antagonists during the show's first two seasons.  They are represented as a nomadic species divided into eighteen separate sects, and characterized by their reliance on violence.  A patriarchal society, the Kazon have a low opinion of women, and place pride in men becoming warriors and proving themselves in battle.  The Kazon storylines frequently revolve around the attempts of Jal Culluh and his Kazon sect to steal technology from the USS \"Voyager\", with the assistance of former \"Voyager\" ensign Seska.  During the second season, the \"Voyager\" crew uncover more about the alien species' history and culture through a temporary truce.  In their final appearance, the Kazon successfully commandeer \"Voyager\", but are eventually forced to surrender and retreat.  The alien species have minor cameo appearances and references in the show's subsequent seasons, and have also been included in \"Star Trek Online\" and novels set in the \"Star Trek\" universe. Victoria Hanley is an American young adult fantasy novelist.  Her first three books, \"The Seer And The Sword\", \"The Healer's Keep\" and \"The Light Of The Oracle\" are companion books to one another.  Her newest book (released March 2012) is the sequel of a series, called \"Indigo Magic\", published by Egmont USA.  She's also published two non-fiction books through Cotton Wood Press; called \"Seize the Story: A Handbook For Teens Who Like To Write\", and \"Wild Ink: A Grownups Guide To Writing Fiction For Teens\". Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn\n",
            "\n",
            "Previous worker summary:\n",
            "No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 1 -- Done\n",
            "Verifying Worker 1\n",
            "Verifying Worker 1 -- Done\n",
            "Running Worker 2\n",
            "Worker 2 with Prompt: \n",
            "######\n",
            "You are Worker 2 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Current source text (CHUNK 2):\n",
            ". Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn.  She is the granddaughter of a \"shadowshaper\", or a person who infuses art with ancestral spirits.  As forces of gentrification invade their community and a mysterious being who appropriates their magic begins to hunt the aging shadowshapers, Sierra must learn about her artistic and spiritual heritage to foil the killer. The Andre Norton Award for Young Adult Science Fiction and Fantasy is an annual award presented by the Science Fiction and Fantasy Writers of America (SFWA) to the author of the best young adult or middle grade science fiction or fantasy book published in the United States in the preceding year.  It is named to honor prolific science fiction and fantasy author Andre Norton (1912–2005), and it was established by then SFWA president Catherine Asaro and the SFWA Young Adult Fiction committee and announced on February 20, 2005.  Any published young adult or middle grade science fiction or fantasy novel is eligible for the prize, including graphic novels.  There is no limit on word count.  The award is presented along with the Nebula Awards and follows the same rules for nominations and voting; as the awards are separate, works may be simultaneously nominated for both the Andre Norton award and a Nebula Award. Etiquette & Espionage is a young adult steampunk novel by Gail Carriger.  It is her first young adult novel, and is set in the same universe as her bestselling Parasol Protectorate adult series. Dozens of Square Enix companion books have been produced since 1998, when video game developer Square began to produce books that focused on artwork, developer interviews, and background information on the fictional worlds and characters in its games rather than on gameplay details\n",
            "\n",
            "Previous worker summary:\n",
            "No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 2 -- Done\n",
            "Verifying Worker 2\n",
            "[CoVe][Worker 2] Plan prompt:\n",
            "\n",
            "You are verifying a summary used in a long-context QA pipeline.\n",
            "\n",
            "Original Query: What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Source chunk: . Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn.  She is the granddaughter of a \"shadowshaper\", or a person who infuses art with ancestral spirits.  As forces of gentrification invade their community and a mysterious being who appropriates their magic begins to hunt the aging shadowshapers, Sierra must learn about her artistic and spiritual heritage to foil the killer. The Andre Norton Award for Young Adult Science Fiction and Fantasy is an annual award presented by the Science Fiction and Fantasy Writers of America (SFWA) to the author of the best young adult or middle grade science fiction or fantasy book published in the United States in the preceding year.  It is named to honor prolific science fiction and fantasy author Andre Norton (1912–2005), and it was established by then SFWA president Catherine Asaro and the SFWA Young Adult Fiction committee and announced on February 20, 2005.  Any published young adult or middle grade science fiction or fantasy novel is eligible for the prize, including graphic novels.  There is no limit on word count.  The award is presented along with the Nebula Awards and follows the same rules for nominations and voting; as the awards are separate, works may be simultaneously nominated for both the Andre Norton award and a Nebula Award. Etiquette & Espionage is a young adult steampunk novel by Gail Carriger.  It is her first young adult novel, and is set in the same universe as her bestselling Parasol Protectorate adult series. Dozens of Square Enix companion books have been produced since 1998, when video game developer Square began to produce books that focused on artwork, developer interviews, and background information on the fictional worlds and characters in its games rather than on gameplay details\n",
            "\n",
            "Baseline summary: No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "\n",
            "Task:\n",
            "Generate a small list of concrete verification questions (2–4) that help check:\n",
            "- factual correctness\n",
            "- coverage of key information relevant to the query\n",
            "- absence of unsupported claims\n",
            "Return the verification questions as a numbered list.\n",
            "\n",
            "\n",
            "[CoVe][Worker 2] Verification Questions:\n",
            "['Is the series mentioned in the summary called \"Animorphs\"?', 'Does the summary correctly state that Animorphs is a science fantasy young adult series?', 'Does the summary accurately indicate that the series is narrated in the first person by multiple main characters?', 'Are there any companion books mentioned in the provided source text that narrate the stories of enslaved worlds and alien species? 1. Is the series mentioned in the summary called \"Animorphs\"?', 'Does the summary correctly state that Animorphs is a science fantasy young adult series?']\n",
            "\n",
            "verification q answer: N. <answer to QN>\n",
            "\n",
            "Do not include any text that is not part of this list. 1. No\n",
            "2. Yes\n",
            "3. Yes\n",
            "4. No\n",
            "5. Yes\n",
            "[CoVe][Worker 2] Answers:\n",
            "['N. <answer to QN>\\n\\nDo not include any text that is not part of this list. 1. No\\n2. Yes\\n3. Yes\\n4. No\\n5. Yes']\n",
            "\n",
            "final_prompt: \n",
            "You are revising a summary for a long-context QA pipeline.\n",
            "\n",
            "Original Query: What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Source chunk: . Shadowshaper is a 2015 American urban fantasy young adult novel written by Daniel José Older.  It follows Sierra Santiago, an Afro-Boricua teenager living in Brooklyn.  She is the granddaughter of a \"shadowshaper\", or a person who infuses art with ancestral spirits.  As forces of gentrification invade their community and a mysterious being who appropriates their magic begins to hunt the aging shadowshapers, Sierra must learn about her artistic and spiritual heritage to foil the killer. The Andre Norton Award for Young Adult Science Fiction and Fantasy is an annual award presented by the Science Fiction and Fantasy Writers of America (SFWA) to the author of the best young adult or middle grade science fiction or fantasy book published in the United States in the preceding year.  It is named to honor prolific science fiction and fantasy author Andre Norton (1912–2005), and it was established by then SFWA president Catherine Asaro and the SFWA Young Adult Fiction committee and announced on February 20, 2005.  Any published young adult or middle grade science fiction or fantasy novel is eligible for the prize, including graphic novels.  There is no limit on word count.  The award is presented along with the Nebula Awards and follows the same rules for nominations and voting; as the awards are separate, works may be simultaneously nominated for both the Andre Norton award and a Nebula Award. Etiquette & Espionage is a young adult steampunk novel by Gail Carriger.  It is her first young adult novel, and is set in the same universe as her bestselling Parasol Protectorate adult series. Dozens of Square Enix companion books have been produced since 1998, when video game developer Square began to produce books that focused on artwork, developer interviews, and background information on the fictional worlds and characters in its games rather than on gameplay details\n",
            "\n",
            "Baseline summary: No Previous summaries\n",
            "\n",
            "Animorphs is a science fantasy series of young adult books written by Katherine Applegate and her husband Michael Grant, writing together under the name K. A. Applegate, and published by Scholastic. It is told in first person, with all six main characters taking turns narrating the books through their own perspectives. Horror, war, dehumanization, sanity, morality, innocence, leadership, freedom, and growing up are the core themes of the series. The current chunk does not provide information about companion books narrating the stories of enslaved worlds and alien species. Therefore, there is no additional relevant information to\n",
            "\n",
            "Verification Q&A:\n",
            "Q: Is the series mentioned in the summary called \"Animorphs\"?\n",
            "Does the summary correctly state that Animorphs is a science fantasy young adult series?\n",
            "Does the summary accurately indicate that the series is narrated in the first person by multiple main characters?\n",
            "Are there any companion books mentioned in the provided source text that narrate the stories of enslaved worlds and alien species? 1. Is the series mentioned in the summary called \"Animorphs\"?\n",
            "Does the summary correctly state that Animorphs is a science fantasy young adult series?\n",
            "A: N. <answer to QN>\n",
            "\n",
            "Do not include any text that is not part of this list. 1. No\n",
            "2. Yes\n",
            "3. Yes\n",
            "4. No\n",
            "5. Yes\n",
            "\n",
            "Task:\n",
            "Write a revised summary that:\n",
            "- corrects any factual errors in the baseline summary\n",
            "- adds missing key information supported by the source chunk\n",
            "- removes unsupported or speculative claims\n",
            "- remains concise and focused on information relevant to the question\n",
            "\n",
            "Return ONLY the revised summary.\n",
            "\n",
            "[CoVe][Worker 2] Final verified summary:\n",
            "Animorphs is a science fantasy young adult series written by K.A. Applegate. The series is narrated in the first person, with each book featuring a different main character's perspective. However, the source chunk does not provide information about companion books that narrate the stories of enslaved worlds and alien species. To find such information, further research would be necessary. 1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "1. No\n",
            "2. Yes\n",
            "3. Yes\n",
            "4. No\n",
            "5. Yes\n",
            "\n",
            "Revised Summary:\n",
            "Animorphs is a science fantasy young adult series written by K.A. Applegate. The\n",
            "\n",
            "Verifying Worker 2 -- Done\n",
            "Running Worker 3\n",
            "Worker 3 with Prompt: \n",
            "######\n",
            "You are Worker 3 in a chain solving a long-context question answering task.\n",
            "\n",
            "Use ONLY:\n",
            "- the current source text (chunk)\n",
            "- the previous worker summary\n",
            "\n",
            "Task:\n",
            "- Write a new summary that combines:\n",
            "  (a) all information from the previous summary that is relevant to the query, and\n",
            "  (b) any new relevant information in the current chunk.\n",
            "- If the current chunk adds no new relevant information, simply repeat the previous summary unchanged.\n",
            "\n",
            "Constraints:\n",
            "- Maximum length: about 300 tokens.\n",
            "- Output only the new summary, no commentary about your process.\n",
            "\n",
            "Query:\n",
            "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Current source text (CHUNK 3):\n",
            ".  The first series of these books was the \"Perfect Works\" series, written and published by Square subsidiary DigiCube.  They produced three books between 1998 and 1999 before the line was stopped in favor of the \"Ultimania\" (アルティマニア , Arutimania ) series, a portmanteau of ultimate and mania.  This series of books is written by Studio BentStuff, which had previously written game guides for Square for \"Final Fantasy VII\".  They were published by DigiCube until the company was dissolved in 2003.  Square merged with video game publisher Enix on April 1, 2003 to form Square Enix, which resumed publication of the companion books. \"Left Behind: The Kids (stylized as LEFT BEHIND >THE KIDS<)\" is a series written by Jerry B. Jenkins, Tim LaHaye, and Chris Fabry.  The series consists of 40 short novels aimed primarily at the young adult market based on the adult series Left Behind also written by Jerry B. Jenkins.  It follows a core group of teenagers as they experience the rapture and tribulation, based on scriptures found in the Bible, and background plots introduced in the adult novels.  Like the adult series, the books were published by Tyndale House Publishing, and released over the 7 year period of 1997-2004.  The series has sold over 11 million copies worldwide.\n",
            "\n",
            "Previous worker summary:\n",
            "Animorphs is a science fantasy young adult series written by K.A. Applegate. The series is narrated in the first person, with each book featuring a different main character's perspective. However, the source chunk does not provide information about companion books that narrate the stories of enslaved worlds and alien species. To find such information, further research would be necessary. 1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "1. No\n",
            "2. Yes\n",
            "3. Yes\n",
            "4. No\n",
            "5. Yes\n",
            "\n",
            "Revised Summary:\n",
            "Animorphs is a science fantasy young adult series written by K.A. Applegate. The\n",
            "\n",
            "Now output the combined summary:\n",
            "\n",
            "#######\n",
            "\n",
            "worker invoke\n",
            "worker invoke -- done\n",
            "Outputs: Animorphs is a science fantasy young adult series written by K.A. Applegate. The series is narrated in the first person, with each book featuring a different main character's perspective. However, the source chunk does not provide information about companion books that narrate the stories of enslaved worlds and alien species. To find such information, further research would be necessary. The current chunk discusses other book series unrelated to Animorphs, including Perfect Works and Ultimania series related to video games, and the Left Behind: The Kids series, which is a religious fiction series aimed at young adults. None of this information pertains to the\n",
            "------------------\n",
            "\n",
            "\n",
            "Running Worker 3 -- Done\n",
            "Verifying Worker 3\n",
            "Verifying Worker 3 -- Done\n",
            "Manager producing output\n",
            "Manager with Prompt: \n",
            "######\n",
            "You are the Manager in a HotpotQA question answering system.\n",
            "\n",
            "Task:\n",
            "- Read the summary of evidence.\n",
            "- Reason briefly about the answer.\n",
            "- Then output the final answer as a short span, try to find the closest answer.\n",
            "\n",
            "Output format (very important):\n",
            "1. First, write a short reasoning paragraph if needed.\n",
            "2. On the LAST line of your response, write exactly:\n",
            "\n",
            "   Final answer: <answer>\n",
            "\n",
            "Rules for <answer>:\n",
            "- Use the shortest possible span (a name, location, date, number, or \"yes\"/\"no\").\n",
            "- For yes/no questions, answer exactly \"yes\" or \"no\".\n",
            "- Do NOT add any text after <answer> on that line.\n",
            "- Do NOT write anything after the \"Final answer: ...\" line (no notes, no extra sentences).\n",
            "\n",
            "Query:\n",
            "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "\n",
            "Summary of evidence:\n",
            "Animorphs is a science fantasy young adult series written by K.A. Applegate. The series is narrated in the first person, with each book featuring a different main character's perspective. However, the source chunk does not provide information about companion books that narrate the stories of enslaved worlds and alien species. To find such information, further research would be necessary. The current chunk discusses other book series unrelated to Animorphs, including Perfect Works and Ultimania series related to video games, and the Left Behind: The Kids series, which is a religious fiction series aimed at young adults. None of this information pertains to the\n",
            "\n",
            "#######\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 3/3 [02:17<00:00, 45.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manager Final Output: \n",
            "#############\n",
            "question asked.\n",
            "\n",
            "Reasoning:\n",
            "The provided evidence mentions Animorphs as a science fantasy young adult series that fits the first-person narration criteria. However, it does not mention any companion books that narrate the stories of enslaved worlds and alien species. Therefore, based on the given information, we cannot confirm if Animorphs is the correct answer or if there is another series that matches all the criteria.\n",
            "\n",
            "Final answer: no\n",
            "\n",
            "(Note: The response indicates that the given information does not confirm the existence of such a series, leading to a \"no\" answer based on the available evidence.) \n",
            "\n",
            "Final answer: no\n",
            "Final answer: no\n",
            "Final Answer before process:  question asked.\n",
            "\n",
            "Reasoning:\n",
            "The provided evidence mentions Animorphs as a science fantasy young adult series that fits the first-person narration criteria. However, it does not mention any companion books that narrate the stories of enslaved worlds and alien species. Therefore, based on the given information, we cannot confirm if Animorphs is the correct answer or if there is another series that matches all the criteria.\n",
            "\n",
            "Final answer: no\n",
            "\n",
            "(Note: The response indicates that the given information does not confirm the existence of such a series, leading to a \"no\" answer based on the available evidence.) \n",
            "\n",
            "Final answer: no\n",
            "Final answer: no\n",
            "splitting parsing\n",
            "Manager producing output -- Done\n",
            "Query: What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
            "Final Answer: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "pmjoTw1zuSmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a1b5c7-bad3-462f-bc59-27f7a01fa3ae"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_samples': 3, 'f1': 0.0, 'em': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['f1']"
      ],
      "metadata": {
        "id": "FuZJx7NZwt-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e64cafd-4679-4b6a-9694-4302cce4dfc9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(\":)\")"
      ],
      "metadata": {
        "id": "5brzMePh8fsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84de3c66-3782-44ec-e907-9106abf85b91"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":)\n",
            ":)\n",
            ":)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "print(LOG_PATH)\n",
        "data = []\n",
        "with open(LOG_PATH, \"r\") as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "        print(json.loads(line))\n",
        "\n",
        "print(len(data))\n",
        "print(data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OUvBMpnIum2",
        "outputId": "8b2a5c57-4646-4c28-a2c5-e895075d327a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GenAI/project/logs/hotpotqa_val003.jsonl\n",
            "{'id': '5a8b57f25542995d1e6f1371', 'idx': 0, 'type': 'comparison', 'level': 'hard', 'question': 'Were Scott Derrickson and Ed Wood of the same nationality?', 'gold_answer': 'yes', 'prediction': 'yes', 'f1': 1.0, 'em': 1}\n",
            "{'id': '5a8c7595554299585d9e36b6', 'idx': 1, 'type': 'bridge', 'level': 'hard', 'question': 'What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?', 'gold_answer': 'Chief of Protocol', 'prediction': 'no', 'f1': 0, 'em': 0}\n",
            "{'id': '5a85ea095542994775f606a8', 'idx': 2, 'type': 'bridge', 'level': 'hard', 'question': 'What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?', 'gold_answer': 'Animorphs', 'prediction': 'no\\n\\n(note: the response was generated based on the provided evidence, which did not contain the exact information required to answer the', 'f1': 0, 'em': 0}\n",
            "3\n",
            "{'id': '5a8b57f25542995d1e6f1371', 'idx': 0, 'type': 'comparison', 'level': 'hard', 'question': 'Were Scott Derrickson and Ed Wood of the same nationality?', 'gold_answer': 'yes', 'prediction': 'yes', 'f1': 1.0, 'em': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74-WWWz2JLOK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"[{i}] Questions:{results['questions'][i]}\\nPrediction: {results['predictions'][i]}  ---> Reference: {results['references'][i]}\\n\\n\")"
      ],
      "metadata": {
        "id": "F9T9mve3If2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['contexts'][0]"
      ],
      "metadata": {
        "id": "-gbgG92qxiGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['questions'][0]"
      ],
      "metadata": {
        "id": "-JYv67Zdx6Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['references'][0]"
      ],
      "metadata": {
        "id": "013xNxLfx-On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['predictions'][0]"
      ],
      "metadata": {
        "id": "bvGm1nY5yRd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing committing from google colab"
      ],
      "metadata": {
        "id": "Ls8r2UCByW3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}